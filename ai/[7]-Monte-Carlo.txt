5:"$Sreact.fragment"
6:I[4839,["949","static/chunks/578c2090-175257547869ead6.js","585","static/chunks/b563f954-2e58cc71e37cba32.js","711","static/chunks/8e1d74a4-98d5a7d540bb92c7.js","87","static/chunks/0e762574-bccdf82862895aef.js","839","static/chunks/839-ee0b8cfd2b2dd0ab.js","859","static/chunks/app/%5Btheme%5D/layout-42c83d4b71ae057e.js"],""]
7:I[5244,[],""]
8:I[3866,[],""]
b:I[6213,[],"OutletBoundary"]
d:I[6213,[],"MetadataBoundary"]
f:I[6213,[],"ViewportBoundary"]
11:I[4835,[],""]
1:HL["/_next/static/media/7626ed2c039b2726-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
2:HL["/_next/static/media/a34f9d1faa5f3315-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
3:HL["/_next/static/css/af6a9e4b89fa7c0b.css","style"]
4:HL["/_next/static/css/dd89e605550f760e.css","style"]
0:{"P":null,"b":"GLc5m3w7TedaZMM4mRKfi","p":"","c":["","ai","%5B7%5D-Monte-Carlo"],"i":false,"f":[[["",{"children":[["theme","ai","d"],{"children":[["post","%5B7%5D-Monte-Carlo","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$5","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/af6a9e4b89fa7c0b.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"ko","children":["$","body",null,{"className":"__className_9b822d min-h-screen bg-slate-50 text-blue-950","children":["$","div",null,{"className":"grid grid-cols-[24rem_1fr] auto-rows-auto","children":[["$","nav",null,{"className":"__className_92d895 bg-slate-50 w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed","children":[["$","$L6",null,{"href":"/","children":"tomatoM4to's blog"}],["$","div",null,{"className":"hidden lg:flex items-center","children":[["$","input",null,{"type":"text","className":"w-36 h-7 rounded-full border-2 border-black pl-2","placeholder":"search"}],["$","div",null,{"className":"bg-slate-300 h-10 w-0.5 ml-2"}],["$","$L6",null,{"href":"https://github.com/tomatoM4to/tomatoM4to.github.io","className":"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 16 16","className":"text-2xl cursor-pointer","children":["$undefined",[["$","path","0",{"fillRule":"evenodd","clipRule":"evenodd","d":"M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z","children":[]}]]],"style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]}],["$","button",null,{"className":"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 24 24","className":"text-2xl cursor-pointer","children":["$undefined",[["$","path","0",{"fill":"none","strokeWidth":"2","d":"M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8","children":[]}]]],"style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]}],["$","button",null,{"className":"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 16 16","className":"text-2xl cursor-pointer","children":["$undefined",[["$","path","0",{"d":"M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278","children":[]}],["$","path","1",{"d":"M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z","children":[]}]]],"style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]}]]}]]}],["$","main",null,{"className":"col-span-2","children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}]]}]}]}]]}],{"children":[["theme","ai","d"],["$","$5","c",{"children":[null,"$L9"]}],{"children":[["post","%5B7%5D-Monte-Carlo","d"],["$","$5","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","$0:f:0:1:2:children:0","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]]}],{"children":["__PAGE__",["$","$5","c",{"children":["$La",[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/dd89e605550f760e.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Lb",null,{"children":"$Lc"}]]}],{},null]},null]},null]},null],["$","$5","h",{"children":[null,["$","$5","wCfvdD95vvz5XNlBkG74y",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust"}]]}]]}]]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes"}]]
e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"tomatom4to's Computer Science Blog"}],["$","meta","2",{"name":"description","content":"Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples."}],["$","meta","3",{"name":"author","content":"tomatom4to"}],["$","meta","4",{"name":"keywords","content":"Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development"}],["$","meta","5",{"name":"creator","content":"tomatom4to"}],["$","meta","6",{"name":"robots","content":"index, follow"}],["$","meta","7",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","8",{"rel":"canonical","href":"https://tomatom4to.github.io"}],["$","meta","9",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","10",{"property":"og:title","content":"tomatom4to's Computer Science Blog"}],["$","meta","11",{"property":"og:description","content":"Your gateway to comprehensive computer science knowledge and practical programming skills"}],["$","meta","12",{"property":"og:url","content":"https://tomatom4to.github.io"}],["$","meta","13",{"property":"og:site_name","content":"tomatom4to's CS Blog"}],["$","meta","14",{"property":"og:locale","content":"ko_KR"}],["$","meta","15",{"property":"og:type","content":"website"}],["$","meta","16",{"name":"twitter:card","content":"summary"}],["$","meta","17",{"name":"twitter:title","content":"tomatom4to's Computer Science Blog"}],["$","meta","18",{"name":"twitter:description","content":"Your gateway to comprehensive computer science knowledge and practical programming skills"}],["$","link","19",{"rel":"icon","href":"/icon.ico?3c4912ce8b26c1d6","type":"image/x-icon","sizes":"256x256"}]]
c:null
12:I[5739,["949","static/chunks/578c2090-175257547869ead6.js","585","static/chunks/b563f954-2e58cc71e37cba32.js","711","static/chunks/8e1d74a4-98d5a7d540bb92c7.js","87","static/chunks/0e762574-bccdf82862895aef.js","839","static/chunks/839-ee0b8cfd2b2dd0ab.js","859","static/chunks/app/%5Btheme%5D/layout-42c83d4b71ae057e.js"],"Hamburger"]
9:["$","div",null,{"className":"flex","children":[["$","$L12",null,{"res":[{"isOutLine":false,"firstOrder":1,"secondOrder":-1,"order":"1","title":"Introduction","originalName":"[1]-Introduction"},{"isOutLine":false,"firstOrder":2,"secondOrder":-1,"order":"2","title":"Basis math","originalName":"[2]-Basis-math"},{"isOutLine":true,"firstOrder":2,"secondOrder":1,"order":"2-1","title":"Math with RL","originalName":"[2-1]-Math-with-RL"},{"isOutLine":false,"firstOrder":3,"secondOrder":-1,"order":"3","title":"Q learning","originalName":"[3]-Q-learning"},{"isOutLine":true,"firstOrder":3,"secondOrder":1,"order":"3-1","title":"Basic Concept","originalName":"[3-1]-Basic-Concept"},{"isOutLine":true,"firstOrder":3,"secondOrder":2,"order":"3-2","title":"Greedy action","originalName":"[3-2]-Greedy-action"},{"isOutLine":true,"firstOrder":3,"secondOrder":3,"order":"3-3","title":"Discount factor","originalName":"[3-3]-Discount-factor"},{"isOutLine":true,"firstOrder":3,"secondOrder":4,"order":"3-4","title":"Learning rate","originalName":"[3-4]-Learning-rate"},{"isOutLine":false,"firstOrder":4,"secondOrder":-1,"order":"4","title":"Markov process","originalName":"[4]-Markov-process"},{"isOutLine":false,"firstOrder":5,"secondOrder":-1,"order":"5","title":"Bellman Optimality Equation","originalName":"[5]-Bellman-Optimality-Equation"},{"isOutLine":false,"firstOrder":6,"secondOrder":-1,"order":"6","title":"DP","originalName":"[6]-DP"},{"isOutLine":false,"firstOrder":7,"secondOrder":-1,"order":"7","title":"Monte Carlo","originalName":"[7]-Monte-Carlo"},{"isOutLine":false,"firstOrder":8,"secondOrder":-1,"order":"8","title":"Temporal Difference Learning","originalName":"[8]-Temporal-Difference-Learning"},{"isOutLine":false,"firstOrder":9,"secondOrder":-1,"order":"9","title":"nSTEP Bootstrapping","originalName":"[9]-nSTEP-Bootstrapping"},{"isOutLine":false,"firstOrder":10,"secondOrder":-1,"order":"10","title":"Planning and Learning","originalName":"[10]-Planning-and-Learning"},{"isOutLine":true,"firstOrder":10,"secondOrder":1,"order":"10-1","title":"Function Approximation","originalName":"[10-1]-Function-Approximation"},{"isOutLine":false,"firstOrder":11,"secondOrder":-1,"order":"11","title":"Deep learning","originalName":"[11]-Deep-learning"},{"isOutLine":true,"firstOrder":11,"secondOrder":1,"order":"11-1","title":"Concept","originalName":"[11-1]-Concept"},{"isOutLine":true,"firstOrder":11,"secondOrder":2,"order":"11-2","title":"Newerl Network","originalName":"[11-2]-Newerl-Network"},{"isOutLine":true,"firstOrder":11,"secondOrder":3,"order":"11-3","title":"Loss function","originalName":"[11-3]-Loss-function"},{"isOutLine":true,"firstOrder":11,"secondOrder":4,"order":"11-4","title":"Activation function","originalName":"[11-4]-Activation-function"},{"isOutLine":true,"firstOrder":11,"secondOrder":5,"order":"11-5","title":"Gradient descent","originalName":"[11-5]-Gradient-descent"},{"isOutLine":true,"firstOrder":11,"secondOrder":6,"order":"11-6","title":"Back Propagation","originalName":"[11-6]-Back-Propagation"},{"isOutLine":false,"firstOrder":12,"secondOrder":-1,"order":"12","title":"Q Network","originalName":"[12]-Q-Network"},{"isOutLine":true,"firstOrder":12,"secondOrder":1,"order":"12-1","title":"Frozen Lake","originalName":"[12-1]-Frozen-Lake"},{"isOutLine":true,"firstOrder":12,"secondOrder":2,"order":"12-2","title":"Cartpole","originalName":"[12-2]-Cartpole"},{"isOutLine":false,"firstOrder":13,"secondOrder":-1,"order":"13","title":"DQN","originalName":"[13]-DQN"},{"isOutLine":true,"firstOrder":13,"secondOrder":1,"order":"13-1","title":"Concept","originalName":"[13-1]-Concept"},{"isOutLine":true,"firstOrder":13,"secondOrder":2,"order":"13-2","title":"Cartpole","originalName":"[13-2]-Cartpole"},{"isOutLine":false,"firstOrder":14,"secondOrder":-1,"order":"14","title":"Policy gradient","originalName":"[14]-Policy-gradient"}],"params":{"theme":"ai"}}],["$","aside",null,{"className":"hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain","children":[["$","$L6","1",{"href":"/ai/[1]-Introduction","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["1",". ","Introduction"]}],["$","$L6","2",{"href":"/ai/[2]-Basis-math","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["2",". ","Basis math"]}],["$","$L6","2-1",{"href":"/ai/[2-1]-Math-with-RL","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["2-1",". ","Math with RL"]}],["$","$L6","3",{"href":"/ai/[3]-Q-learning","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["3",". ","Q learning"]}],["$","$L6","3-1",{"href":"/ai/[3-1]-Basic-Concept","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["3-1",". ","Basic Concept"]}],["$","$L6","3-2",{"href":"/ai/[3-2]-Greedy-action","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["3-2",". ","Greedy action"]}],["$","$L6","3-3",{"href":"/ai/[3-3]-Discount-factor","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["3-3",". ","Discount factor"]}],["$","$L6","3-4",{"href":"/ai/[3-4]-Learning-rate","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["3-4",". ","Learning rate"]}],["$","$L6","4",{"href":"/ai/[4]-Markov-process","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["4",". ","Markov process"]}],["$","$L6","5",{"href":"/ai/[5]-Bellman-Optimality-Equation","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["5",". ","Bellman Optimality Equation"]}],["$","$L6","6",{"href":"/ai/[6]-DP","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["6",". ","DP"]}],["$","$L6","7",{"href":"/ai/[7]-Monte-Carlo","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["7",". ","Monte Carlo"]}],["$","$L6","8",{"href":"/ai/[8]-Temporal-Difference-Learning","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["8",". ","Temporal Difference Learning"]}],["$","$L6","9",{"href":"/ai/[9]-nSTEP-Bootstrapping","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["9",". ","nSTEP Bootstrapping"]}],["$","$L6","10",{"href":"/ai/[10]-Planning-and-Learning","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["10",". ","Planning and Learning"]}],["$","$L6","10-1",{"href":"/ai/[10-1]-Function-Approximation","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["10-1",". ","Function Approximation"]}],["$","$L6","11",{"href":"/ai/[11]-Deep-learning","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["11",". ","Deep learning"]}],["$","$L6","11-1",{"href":"/ai/[11-1]-Concept","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["11-1",". ","Concept"]}],["$","$L6","11-2",{"href":"/ai/[11-2]-Newerl-Network","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["11-2",". ","Newerl Network"]}],["$","$L6","11-3",{"href":"/ai/[11-3]-Loss-function","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["11-3",". ","Loss function"]}],["$","$L6","11-4",{"href":"/ai/[11-4]-Activation-function","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["11-4",". ","Activation function"]}],["$","$L6","11-5",{"href":"/ai/[11-5]-Gradient-descent","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["11-5",". ","Gradient descent"]}],["$","$L6","11-6",{"href":"/ai/[11-6]-Back-Propagation","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["11-6",". ","Back Propagation"]}],["$","$L6","12",{"href":"/ai/[12]-Q-Network","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["12",". ","Q Network"]}],["$","$L6","12-1",{"href":"/ai/[12-1]-Frozen-Lake","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["12-1",". ","Frozen Lake"]}],["$","$L6","12-2",{"href":"/ai/[12-2]-Cartpole","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["12-2",". ","Cartpole"]}],["$","$L6","13",{"href":"/ai/[13]-DQN","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["13",". ","DQN"]}],["$","$L6","13-1",{"href":"/ai/[13-1]-Concept","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["13-1",". ","Concept"]}],["$","$L6","13-2",{"href":"/ai/[13-2]-Cartpole","className":"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["13-2",". ","Cartpole"]}],["$","$L6","14",{"href":"/ai/[14]-Policy-gradient","className":"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg","onClick":"$undefined","children":["14",". ","Policy gradient"]}]]}],["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","$0:f:0:1:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]]}]
a:["$","div",null,{"className":"lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden","children":["$","div",null,{"className":"w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body","children":[["$","h1",null,{"children":"How can we get Q*","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500"}],"\n",["$","p",null,{"children":"그래서 Q* 값을 얻을수 있을까? 에 대한 의문이 생깁니다. 사실 단번에 얻는거는 불가능하다 봐야하고, 알고리즘을 통해 수렴 하는 방법을 찾아야 합니다."}],"\n",["$","p",null,{"children":["episode를 진행하면서 Q를 점점 업데이트 하며 Q",["$","em",null,{"children":["에 점점 다가가게 하고, 그러면 최종적으로 ",["$","span",null,{"className":"katex","children":["$","math",null,{"xmlns":"http://www.w3.org/1998/Math/MathML","children":["$","semantics",null,{"children":[["$","mrow",null,{"children":["$","mi",null,{"children":"ϵ"}]}],["$","annotation",null,{"encoding":"application/x-tex","children":"\\epsilon"}]]}]}]}],"하게 greedy 하게 하면 됩니다. 트레이닝이 끝난다면 이 Q값을 Q"]}],"라 믿고 사용하면 됩니다. 더이상 ",["$","span",null,{"className":"katex","children":["$","math",null,{"xmlns":"http://www.w3.org/1998/Math/MathML","children":["$","semantics",null,{"children":[["$","mrow",null,{"children":["$","mi",null,{"children":"ϵ"}]}],["$","annotation",null,{"encoding":"application/x-tex","children":"\\epsilon"}]]}]}]}],"(탐험)을 수행 안해도 됩니다. 물론 잘 안되면 다시 ",["$","span",null,{"className":"katex","children":["$","math",null,{"xmlns":"http://www.w3.org/1998/Math/MathML","children":["$","semantics",null,{"children":[["$","mrow",null,{"children":["$","mi",null,{"children":"ϵ"}]}],["$","annotation",null,{"encoding":"application/x-tex","children":"\\epsilon"}]]}]}]}],"을 수행해야 합니다."]}],"\n",["$","p",null,{"children":"이전 미로찾기 문제에서 Q-learning의 q값을 계속 업데이트 했는데 이 과정이 Q*를 찾기 위한 과정입니다."}],"\n",["$","p",null,{"children":"이렇듯 여러번 수많은 episode를 통해 Q*를 구하는 방법에는 크게 2가지가 있습니다. 그중 첫번쨰인 Monte-Carlo 방법에 대해 알아보겠습니다."}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"Monte-Carlo Methods","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"학습 방법","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500"}],"\n",["$","p",null,{"children":"다이나믹 프로그래밍 =! 강화학습이란걸 알아야함, 따로따로 발발전하다 나나중에 합친 사람이 대단한거지"}],"\n",["$","p",null,{"children":"프리딕션 == 애벌루에이션, 똑같은의미임"}],"\n",["$","p",null,{"children":"S0 -> A0: 여기서파이(S0) 수행 후-> R0"}],"\n",["$","p",null,{"children":"애피소드라는걸 다 알수 있단거는, 지금까지 아는대 한에선수익을 전부 알수있다"}],"\n",["$","h1",null,{"children":"First visitVS. Every visit","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500"}],"\n",["$","p",null,{"children":"미로찾기에서 만약내가 왔던길을 다시 가거 다시 반복하는 x1 -> x2 -> x1 -> x2.."}],"\n",["$","p",null,{"children":"이런식으로 됄때 어느걸 선택할가에 대한 것"}],"\n",["$","hr",null,{}],"\n",["$","p",null,{"children":"몬테 카를로는 수렴할때까지 하지 않않음, 그래서 의사코드에서 while 빼고 그냥 마노이 돌돌려도됌"}],"\n",["$","p",null,{"children":"환환경이 없기 때문문에 강화학습에선 행동 가치함수만 사용하게 됀다."}],"\n",["$","p",null,{"children":"몬테카를로에선 우리가 아는 부분에서만 가능하고, 모르는애들한테는 모모름, 환경을 아예 모르기 때문에"}],"\n",["$","p",null,{"children":"모르는 애들들한테 어떤 정책? 행행동을 수행할지지에 대해선 모험과 착취가 있겠는데"}],"\n",["$","p",null,{"children":"입실론 Greedy라고더 괜찮은 방법이 있음"}],"\n",["$","p",null,{"children":"몬테카를로에선 현재의 정책이 과거의 정책보다 더 좋다는걸 알수 이어야한다."}],"\n",["$","p",null,{"children":"입실론 그리디를 했을때, 과거의 정책볻 현재가 더 좋다는걸 증명, 알수 있을까?"}],"\n",["$","p",null,{"children":"결국 최적의 정책으 찾을수 있는지?"}],"\n",["$","p",null,{"children":"시시그마 파이((a'|s) -e/||A|)/1-e= 1"}],"\n",["$","p",null,{"children":"온폴리시 몬테카카를로의 문제는 e/|A| 확률로만 탐험을 하게 됀다, 한마디로 자기가 아는 조그만 지식 내에서 몬갈 하는데 결국 탐험이 부족함"}],"\n",["$","p",null,{"children":"Off Policy가 강화학습에서 대부분 사용됌, 근데 좀 느리긴 함"}],"\n",["$","p",null,{"children":"예를들어 과제기간 3일남았는데 Off policy 쓰면 과제 못함, 학습시간이 3일, 2일이면 On policy 써야 함"}],"\n",["$","p",null,{"children":"DP랑 강화학습은 사실 완전히 다른 방향으로 발전했고 일부분 비슷한게 있어서 배운것 뿐이지 사실 그그냥  다른거임"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"Off-Policy Monye-Calo Methods","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500"}],"\n",["$","p",null,{"children":"최적의 정책을 찾는 문제의 딜레마가 있음, 최적의 행동에 대한 가치함수를 학습을 해야함, V*를 알아야 함, 근데 이걸 하려면 최적이 아닌 행동을 해야함."}],"\n",["$","p",null,{"children":"On-Policy는 그래서 최적의 행동에 대한 가치 함수를 학습하는 대신..(ppt 내용용"}],"\n",["$","p",null,{"children":"Behavior Policy는 에피소드를 다음과 같이 생성: 배울 필요 없음, 그냥 아무거나 막 생성함 다 같은확률로"}],"\n",["$","p",null,{"children":"감마(s) 는 현재 시간에 대한 타임스탬프/ V파이(s) 가 아니라 사실 Vb(s) 다?"}],"\n",["$","p",null,{"children":"핵심: 파랑줄"}],"\n",["$","hr",null,{}],"\n",["$","h2",null,{"children":"Importance Sampling","className":" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200"}],"\n",["$","p",null,{"children":"Gt: 랜덤 긷댓값, ㄱ냥 랜덤값?"}],"\n",["$","h2",null,{"children":"Estimtor","className":" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200"}],"\n",["$","p",null,{"children":"사실 이러한 과저이 그렇게 간단하진 않음"}],"\n",["$","p",null,{"children":"T(t) 에피소드가 언제끝났냐에대한 예기임"}],"\n",["$","p",null,{"children":"공식상으론 맞는데 분산이 커지는걸 막아야함 -> 분모를 증가시켜야함"}],"\n",["$","p",null,{"children":"[다음 ppt장]그래서 Off Policy 몬테카를를로 방식을 살거면 무지성으로 이걸 쓰면 잘 됀다."}],"\n",["$","p",null,{"children":"왜 지금까지 V파이를 계산했나요 Q파이를 계계산하지, 더 짧으니까.. 비슷하게 생겼으니까.. V를 Q로, a 추가가하면 끝이니까"}],"\n",["$","h2",null,{"children":"Peudocode","className":" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200"}],"\n",["$","h2",null,{"children":"Importance Sampling","className":" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200"}],"\n",["$","p",null,{"children":"감마: 할인율을 고려 안한 문문제가 발생해서 고려해야함"}],"\n",["$","p",null,{"children":"여기서 수식중에 - 여야 하는게 +로 써져있는 오류가 있음"}],"\n",["$","p",null,{"children":"오더네리 펄 디시션 어쩌구[마지막 ppt 내용용"}],"\n",["$","p",null,{"children":"증명명돼지 않고.. 그냥 잘 돼더라"}],"\n",["$","p",null,{"children":"옾폴리시 몬테 카를를로는 아직연구가  많이 필요하다 한다."}],"\n",["$","p",null,{"children":"실제론 MC 보단 TD를 많이 씀, 아마 과제도 TD를 할할거임"}]]}]}]
