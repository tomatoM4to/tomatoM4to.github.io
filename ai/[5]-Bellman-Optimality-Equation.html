<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes"/><link rel="preload" href="/_next/static/media/7626ed2c039b2726-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/cd2f1fb5b39214bb.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/dd89e605550f760e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-d0d9b48754bc8658.js"/><script src="/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/_next/static/chunks/23-a9892337a8234d4f.js" async=""></script><script src="/_next/static/chunks/main-app-ce18d4723c8629f4.js" async=""></script><script src="/_next/static/chunks/578c2090-c1b891f3b6c746fd.js" async=""></script><script src="/_next/static/chunks/b563f954-758761ebc4ecc2e7.js" async=""></script><script src="/_next/static/chunks/8e1d74a4-44e18cb83de8b273.js" async=""></script><script src="/_next/static/chunks/0e762574-0fedad6633d82a8a.js" async=""></script><script src="/_next/static/chunks/231-87925b9c7247c60f.js" async=""></script><script src="/_next/static/chunks/app/%5Btheme%5D/layout-721fb6b39c6c5125.js" async=""></script><title>tomatom4to&#x27;s Computer Science Blog</title><meta name="description" content="Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples."/><meta name="author" content="tomatom4to"/><meta name="keywords" content="Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development"/><meta name="creator" content="tomatom4to"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://tomatom4to.github.io"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta property="og:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><meta property="og:url" content="https://tomatom4to.github.io"/><meta property="og:site_name" content="tomatom4to&#x27;s CS Blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta name="twitter:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><link rel="icon" href="/icon.ico?3c4912ce8b26c1d6" type="image/x-icon" sizes="256x256"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_9b822d min-h-screen bg-slate-100 text-blue-950"><div class="grid grid-cols-[24rem_1fr] auto-rows-auto"><nav class="__className_92d895 bg-slate-100 w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed"><a href="/">tomatoM4to&#x27;s blog</a><div class="hidden lg:flex items-center"><input type="text" class="w-36 h-7 rounded-full border-2 border-black pl-2" placeholder="search"/><div class="bg-slate-300 h-10 w-0.5 ml-2"></div><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button></div></nav><main class="col-span-2"><div class="flex"><aside class="lg:hidden"><button class=" flex flex-col gap-1 justify-center items-center w-10 h-10 rounded-lg fixed right-2 top-2 active:outline-none p-2 hover:bg-gray-200 transition-all" style="z-index:15"><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span><span class="w-6 h-0.5 bg-black rounded transition-opacity duration-300 ease-in-out opacity-100"></span><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span></button><div class="
                bg-slate-100
                fixed
                top-0
                right-0
                flex
                flex-col
                px-5
                h-full
                w-7/12
                shadow-lg
                transform
                transition-transform
                duration-300
                ease-in-out
                translate-x-full
                " style="z-index:10"><nav class="h-14 flex items-center border-b-2"><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"></path></svg></button></nav><div class="pb-5 flex flex-col overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-Introduction">1<!-- -->. <!-- -->Introduction</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-1]-Basic-Concept">3-1<!-- -->. <!-- -->Basic Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-2]-Greedy-action">3-2<!-- -->. <!-- -->Greedy action</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-3]-Discount-factor">3-3<!-- -->. <!-- -->Discount factor</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-4]-Learning-rate">3-4<!-- -->. <!-- -->Learning rate</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning">11<!-- -->. <!-- -->Deep learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Concept">11-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-2]-Newerl-Network">11-2<!-- -->. <!-- -->Newerl Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-3]-Loss-function">11-3<!-- -->. <!-- -->Loss function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-4]-Activation-function">11-4<!-- -->. <!-- -->Activation function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-5]-Gradient-descent">11-5<!-- -->. <!-- -->Gradient descent</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-6]-Back-Propagation">11-6<!-- -->. <!-- -->Back Propagation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12]-Q-Network">12<!-- -->. <!-- -->Q Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-1]-Frozen-Lake">12-1<!-- -->. <!-- -->Frozen Lake</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-2]-Cartpole">12-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13]-DQN">13<!-- -->. <!-- -->DQN</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-1]-Concept">13-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-2]-Cartpole">13-2<!-- -->. <!-- -->Cartpole</a></div></div><div class="
        w-screen
        h-screen
        bg-white
        blur-lg
        fixed
        left-0
        top-0
        transition-opacity
        duration-300
        opacity-0 pointer-events-none" style="z-index:5"></div></aside><aside class="hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-Introduction">1<!-- -->. <!-- -->Introduction</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-1]-Basic-Concept">3-1<!-- -->. <!-- -->Basic Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-2]-Greedy-action">3-2<!-- -->. <!-- -->Greedy action</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-3]-Discount-factor">3-3<!-- -->. <!-- -->Discount factor</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-4]-Learning-rate">3-4<!-- -->. <!-- -->Learning rate</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning">11<!-- -->. <!-- -->Deep learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Concept">11-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-2]-Newerl-Network">11-2<!-- -->. <!-- -->Newerl Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-3]-Loss-function">11-3<!-- -->. <!-- -->Loss function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-4]-Activation-function">11-4<!-- -->. <!-- -->Activation function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-5]-Gradient-descent">11-5<!-- -->. <!-- -->Gradient descent</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-6]-Back-Propagation">11-6<!-- -->. <!-- -->Back Propagation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12]-Q-Network">12<!-- -->. <!-- -->Q Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-1]-Frozen-Lake">12-1<!-- -->. <!-- -->Frozen Lake</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-2]-Cartpole">12-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13]-DQN">13<!-- -->. <!-- -->DQN</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-1]-Concept">13-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-2]-Cartpole">13-2<!-- -->. <!-- -->Cartpole</a></aside><div class="lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden"><div class="w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body"><h1 class="text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">상태 가치 함수 &amp; 행동 가치 함수</h1>
<p>이 두가지 함수를 한문장으로 요약하면 이겁니다 <strong>Expected return</strong>을 잘 표현하기 위한 함수입니다.</p>
<ul class="list-disc ml-12 space-y-2 my-3">
<li>State Value Function: 지금 이 순간, 지금 이 State 로부터 시작해서 기대되는 Return 값<!-- -->
<ul class="list-disc ml-12 space-y-2 my-3">
<li>현재 state가 주어져 있을때 Return을 계산하는것, 또는 지금 현재 State에 대한 평가(가치)를 내리는거라 볼수도 있습니다.</li>
</ul>
</li>
<li>Action Value Function: 지금 State에서 지금 어떠한 행동으로부터 기대되는 Return<!-- -->
<ul class="list-disc ml-12 space-y-2 my-3">
<li>이전 Q-learning 시간에서 이동하는 행동에 대해 점수를 매겼늗데. 이것이 Action Value Function 입니다. 즉 Q의 정체입니다.</li>
</ul>
</li>
<li>Optimal Policy: State Value Function 값을 최대화 Policy, 과거는 잊고 지금부터 기대되는 Return을 최대화 하는것, 과거는 지금 시점에서 잘했다 치고 미래를 계산하는것 입니다. 딴예기지만 과거미래현재중 어떤게 중요할까요, 현재부터 잘하자란 예기입니다.</li>
</ul>
<h2 class="text-3xl font-bold my-5 text-purple-700 hover:text-purple-900 transition-colors duration-200">State Value Function</h2>
<p>개념은 저게 전부입니다. 이제부턴 수식적으로 이해해보겠습니다.</p>
<p><strong>Return</strong> 의 정의부터 알아보겠습니다.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>G</mi><mi>t</mi></msub><mo>=</mo><msub><mi>R</mi><mi>t</mi></msub><mo>+</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>3</mn></mrow></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><msup><mi>γ</mi><mi>k</mi></msup><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_t = R_t + R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + ... = \sum_{k=0}^{\infty} \gamma^k R_{t+k}
</annotation></semantics></math></span>
<p>Expectation을 구하는 공식을 다시한번 기억해 보겠습니다. <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E[x]</annotation></semantics></math></span>은 도수(frequency)에 확률을 곱해서 더한것입니다. 다음은 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span>에 대한 기대값을 구하는 공식입니다.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>X</mi><mo stretchy="false">]</mo><mo>=</mo><munder><mo>∑</mo><mi>x</mi></munder><mi>x</mi><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E[X] = \sum_{x} x P(x)
</annotation></semantics></math></span>
<p>이제 이 <strong>Return</strong>에 기대값을 취해보겠습니다.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>V</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow></mrow><mi mathvariant="normal">∞</mi></munderover><msub><mi>G</mi><mi>t</mi></msub><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><mo>…</mo><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V_{\pi}(s_t) = \sum_{}^{\infty} G_t * P(a_t, s_{t+1}, a_{t+1}, s_{t+2}, \dots | s_t)
</annotation></semantics></math></span>
<p>해당 공식을 부분적으로 해석해 보겠습니다.</p>
<ul class="list-disc ml-12 space-y-2 my-3">
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><mo>…</mo><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(a_t, s_{t+1}, a_{t+1}, s_{t+2}, \dots | s_t)</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span>는 현재 State를 나타냅니다. 현재 State 에서 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span>라는 행동을 했고 이 행동은 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{t+1}</annotation></semantics></math></span>로 이동했습니다. 그리고 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">a_{t+1}</annotation></semantics></math></span>로 행동을 했습니다. <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span> 는 끝까지 같다, 에피소드가 끝났다 라는 뜻입니다.</li>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">G_t</annotation></semantics></math></span>: 현재 State에서 시작해서 끝까지의 Return 값입니다. 위에서 설명한 state아 action들은 전부 random variable 입니다. 그래서 이들의 모든 행동, 어떤 상태에서 이행동도 해보고 저행동도 해보고, 저상태에서 이행동도 해보고 저행동도 해보고.. 할수있는 action, 나올수 있는 state에 대한 모든걸 전부 계산해서 나온 Return에 대한 값 입니다.</li>
</ul>
<p>이 모든것들을 전부 더해서 나온것이 <strong>State Value Function</strong> 의 값입니다. 이것은 <strong>Expected Return</strong>이고, 지금부터 미래까지의 Return을 계산한것입니다.</p>
<h2 class="text-3xl font-bold my-5 text-purple-700 hover:text-purple-900 transition-colors duration-200">Action Value Function</h2>
<p>아까는 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span>에 대한 함수였다면 이번에는 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t, a_t</annotation></semantics></math></span>에 대한 함수입니다. 현재 State에서 어떤 행동을 했을때의 Return 값을 계산하기 위함이기 때문입니다.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span>를 앞에다 놨는데 Q-learning에서 배웠던 Q값들의 개념이 바로 이것입니다. Q-learning에서는 이 Q값을 학습하는것이 목표였습니다.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Q</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow></mrow><mi mathvariant="normal">∞</mi></munderover><msub><mi>G</mi><mi>t</mi></msub><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>…</mo><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_{\pi}(s_t, a_t) = \sum_{}^{\infty} G_t * P(s_{t+1}, a_{t+1}, s_{t+2}, a_{t+2} \dots | s_t, a_t)
</annotation></semantics></math></span>
<p>위와 거의 동일합니다. 볼수 있듯이 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t, a_t</annotation></semantics></math></span>에 대한 함수입니다. 위에것은 현재 State에서 진행항것이고, 이것은 현재 State에서 어떤 행동을 했을때 쭉 진행을 해본 기댓값 입니다.</p>
<hr/>
<p>ref: <a href="https://ai-sinq.tistory.com/entry/Bellman-Equation%EB%B2%A8%EB%A7%8C-%EB%B0%A9%EC%A0%95%EC%8B%9D">https://ai-sinq.tistory.com/entry/Bellman-Equation%EB%B2%A8%EB%A7%8C-%EB%B0%A9%EC%A0%95%EC%8B%9D</a></p>
<h1 class="text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">벨만 방정식(Bellman Equation)</h1>
<p>벨만 방정식을 요약하면 다음과 같습니다. <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V_{\pi}(s_t)</annotation></semantics></math></span> 를 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_{\pi}(s_t, a_t)</annotation></semantics></math></span> 로 표현하는것, 혹은 그 반대, 아니면 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V_{\pi}(s_t)</annotation></semantics></math></span>를 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V_{\pi}(s_{t+1})</annotation></semantics></math></span>로 표현하는것, 혹은 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_{\pi}(s_t, a_t)</annotation></semantics></math></span>를 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_{\pi}(s_{t+1}, a_{t+1})</annotation></semantics></math></span>로 표현하는것입니다. 이것이 바로 벨만 방정식에 대한 간단한 요약 입니다.</p>
<h2 class="text-3xl font-bold my-5 text-purple-700 hover:text-purple-900 transition-colors duration-200"><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V_{\pi}(s_t)</annotation></semantics></math></span> to <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>π</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_{\pi}(s_t, a_t)</annotation></semantics></math></span></h2>
<p>TODO: 모라는거야</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>v</mi><mi>π</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow></munder><mi>π</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><msub><mi>q</mi><mi>π</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">v_\pi(s) = \sum_{a \in A} \pi(a|s) q_\pi(s, a)
</annotation></semantics></math></span>
<p>이전 Q-learning를 예로들어 설명해보면, 한 격자에 Q값이 상하좌우 4개 있었죠? 그 값들의 평균치가 그 상태, 그 격자에서부터 기대되는 기댓값, 그 상태에서부터 기대되는 기대값이 되는겁니다.</p>
<hr/>
<h1 class="text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">Optimal Policy</h1>
<hr/>
<hr/>
<hr/>
<h1 class="text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">정책</h1>
<p>지금까지 정책을 많이 있는것처럼 말했지만 입입실론-Greedy 정책의, 결정적 정책과 확률적 정책이 전부라고 할수 있다.</p>
<p>이중ㅇ서 greedy 정책을의외로 많이 쓴데, 대부분</p>
<p>결정적 정책에서 argmax(qx...) 를 보면 지금까지 저누 배웠지만 q를 모른다.</p>
<p>즉 q를 학습하는것이 최적의 정책을 학습하는거다??? 이 줄은 애매하다..</p>
<p>Gt(액센 벨류 펑션) Gt + 1 는 다르다. Gt + 1 을 Gt(액션 벨류 펑션션 으로 바꿔줘야 한다.</p>
<p>정책에 대해 오해해할수 이는는게 정책은 어디까지나 탐험험이고 자의적으로 끝날수 있는게 아님, 탐험이 끝났다면 선택 정책으로? 바꿔야함</p>
<hr/>
<h1 class="text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">최적</h1>
<p>이론적으로 존재하는 최적 상태 즉 참인상태로 실제로 우리가 알수 있는건 아님, 이 최적 상태를 이론적으로 알기 위해 학습을 하는거기도 함</p></div></div></div></main></div><script src="/_next/static/chunks/webpack-d0d9b48754bc8658.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/7626ed2c039b2726-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/css/cd2f1fb5b39214bb.css\",\"style\"]\n4:HL[\"/_next/static/css/dd89e605550f760e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"5:I[5751,[],\"\"]\n8:I[9275,[],\"\"]\nb:I[1343,[],\"\"]\nd:I[231,[\"217\",\"static/chunks/578c2090-c1b891f3b6c746fd.js\",\"675\",\"static/chunks/b563f954-758761ebc4ecc2e7.js\",\"699\",\"static/chunks/8e1d74a4-44e18cb83de8b273.js\",\"779\",\"static/chunks/0e762574-0fedad6633d82a8a.js\",\"231\",\"static/chunks/231-87925b9c7247c60f.js\",\"575\",\"static/chunks/app/%5Btheme%5D/layout-721fb6b39c6c5125.js\"],\"\"]\nf:I[6130,[],\"\"]\n9:[\"theme\",\"ai\",\"d\"]\na:[\"post\",\"%5B5%5D-Bellman-Optimality-Equation\",\"d\"]\n10:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/cd2f1fb5b39214bb.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"ECxp3As9HUbt-yAs4xd61\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/%5B5%5D-Bellman-Optimality-Equation\",\"initialTree\":[\"\",{\"children\":[[\"theme\",\"ai\",\"d\"],{\"children\":[[\"post\",\"%5B5%5D-Bellman-Optimality-Equation\",\"d\"],{\"children\":[\"__PAGE__?{\\\"theme\\\":\\\"ai\\\",\\\"post\\\":\\\"[5]-Bellman-Optimality-Equation\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"theme\",\"ai\",\"d\"],{\"children\":[[\"post\",\"%5B5%5D-Bellman-Optimality-Equation\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L6\",\"$L7\"],null],null]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$9\",\"children\",\"$a\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/dd89e605550f760e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],null]},[\"$Lc\",null],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_9b822d min-h-screen bg-slate-100 text-blue-950\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-[24rem_1fr] auto-rows-auto\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"__className_92d895 bg-slate-100 w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed\",\"children\":[[\"$\",\"$Ld\",null,{\"href\":\"/\",\"children\":\"tomatoM4to's blog\"}],[\"$\",\"div\",null,{\"className\":\"hidden lg:flex items-center\",\"children\":[[\"$\",\"input\",null,{\"type\":\"text\",\"className\":\"w-36 h-7 rounded-full border-2 border-black pl-2\",\"placeholder\":\"search\"}],[\"$\",\"div\",null,{\"className\":\"bg-slate-300 h-10 w-0.5 ml-2\"}],[\"$\",\"$Ld\",null,{\"href\":\"https://github.com/tomatoM4to/tomatoM4to.github.io\",\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 24 24\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fill\":\"none\",\"strokeWidth\":\"2\",\"d\":\"M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278\",\"children\":[]}],[\"$\",\"path\",\"1\",{\"d\":\"M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]]}]]}],[\"$\",\"main\",null,{\"className\":\"col-span-2\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$Le\"],\"globalErrorComponent\":\"$f\",\"missingSlots\":\"$W10\"}]]\n"])</script><script>self.__next_f.push([1,"11:I[1815,[\"217\",\"static/chunks/578c2090-c1b891f3b6c746fd.js\",\"675\",\"static/chunks/b563f954-758761ebc4ecc2e7.js\",\"699\",\"static/chunks/8e1d74a4-44e18cb83de8b273.js\",\"779\",\"static/chunks/0e762574-0fedad6633d82a8a.js\",\"231\",\"static/chunks/231-87925b9c7247c60f.js\",\"575\",\"static/chunks/app/%5Btheme%5D/layout-721fb6b39c6c5125.js\"],\"Hamburger\"]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"10\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:title\",\"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:url\",\"content\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:site_name\",\"content\":\"tomatom4to's CS Blog\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:title\",\"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/icon.ico?3c4912ce8b26c1d6\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"6:null\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"div\",null,{\"className\":\"flex\",\"children\":[[\"$\",\"$L11\",null,{\"res\":[{\"isOutLine\":false,\"firstOrder\":1,\"secondOrder\":-1,\"order\":\"1\",\"title\":\"Introduction\",\"originalName\":\"[1]-Introduction\"},{\"isOutLine\":false,\"firstOrder\":2,\"secondOrder\":-1,\"order\":\"2\",\"title\":\"Basis math\",\"originalName\":\"[2]-Basis-math\"},{\"isOutLine\":true,\"firstOrder\":2,\"secondOrder\":1,\"order\":\"2-1\",\"title\":\"Math with RL\",\"originalName\":\"[2-1]-Math-with-RL\"},{\"isOutLine\":false,\"firstOrder\":3,\"secondOrder\":-1,\"order\":\"3\",\"title\":\"Q learning\",\"originalName\":\"[3]-Q-learning\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":1,\"order\":\"3-1\",\"title\":\"Basic Concept\",\"originalName\":\"[3-1]-Basic-Concept\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":2,\"order\":\"3-2\",\"title\":\"Greedy action\",\"originalName\":\"[3-2]-Greedy-action\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":3,\"order\":\"3-3\",\"title\":\"Discount factor\",\"originalName\":\"[3-3]-Discount-factor\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":4,\"order\":\"3-4\",\"title\":\"Learning rate\",\"originalName\":\"[3-4]-Learning-rate\"},{\"isOutLine\":false,\"firstOrder\":4,\"secondOrder\":-1,\"order\":\"4\",\"title\":\"Markov process\",\"originalName\":\"[4]-Markov-process\"},{\"isOutLine\":false,\"firstOrder\":5,\"secondOrder\":-1,\"order\":\"5\",\"title\":\"Bellman Optimality Equation\",\"originalName\":\"[5]-Bellman-Optimality-Equation\"},{\"isOutLine\":false,\"firstOrder\":6,\"secondOrder\":-1,\"order\":\"6\",\"title\":\"DP\",\"originalName\":\"[6]-DP\"},{\"isOutLine\":false,\"firstOrder\":7,\"secondOrder\":-1,\"order\":\"7\",\"title\":\"Monte Carlo\",\"originalName\":\"[7]-Monte-Carlo\"},{\"isOutLine\":false,\"firstOrder\":8,\"secondOrder\":-1,\"order\":\"8\",\"title\":\"Temporal Difference Learning\",\"originalName\":\"[8]-Temporal-Difference-Learning\"},{\"isOutLine\":false,\"firstOrder\":9,\"secondOrder\":-1,\"order\":\"9\",\"title\":\"nSTEP Bootstrapping\",\"originalName\":\"[9]-nSTEP-Bootstrapping\"},{\"isOutLine\":false,\"firstOrder\":10,\"secondOrder\":-1,\"order\":\"10\",\"title\":\"Planning and Learning\",\"originalName\":\"[10]-Planning-and-Learning\"},{\"isOutLine\":true,\"firstOrder\":10,\"secondOrder\":1,\"order\":\"10-1\",\"title\":\"Function Approximation\",\"originalName\":\"[10-1]-Function-Approximation\"},{\"isOutLine\":false,\"firstOrder\":11,\"secondOrder\":-1,\"order\":\"11\",\"title\":\"Deep learning\",\"originalName\":\"[11]-Deep-learning\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":1,\"order\":\"11-1\",\"title\":\"Concept\",\"originalName\":\"[11-1]-Concept\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":2,\"order\":\"11-2\",\"title\":\"Newerl Network\",\"originalName\":\"[11-2]-Newerl-Network\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":3,\"order\":\"11-3\",\"title\":\"Loss function\",\"originalName\":\"[11-3]-Loss-function\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":4,\"order\":\"11-4\",\"title\":\"Activation function\",\"originalName\":\"[11-4]-Activation-function\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":5,\"order\":\"11-5\",\"title\":\"Gradient descent\",\"originalName\":\"[11-5]-Gradient-descent\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":6,\"order\":\"11-6\",\"title\":\"Back Propagation\",\"originalName\":\"[11-6]-Back-Propagation\"},{\"isOutLine\":false,\"firstOrder\":12,\"secondOrder\":-1,\"order\":\"12\",\"title\":\"Q Network\",\"originalName\":\"[12]-Q-Network\"},{\"isOutLine\":true,\"firstOrder\":12,\"secondOrder\":1,\"order\":\"12-1\",\"title\":\"Frozen Lake\",\"originalName\":\"[12-1]-Frozen-Lake\"},{\"isOutLine\":true,\"firstOrder\":12,\"secondOrder\":2,\"order\":\"12-2\",\"title\":\"Cartpole\",\"originalName\":\"[12-2]-Cartpole\"},{\"isOutLine\":false,\"firstOrder\":13,\"secondOrder\":-1,\"order\":\"13\",\"title\":\"DQN\",\"originalName\":\"[13]-DQN\"},{\"isOutLine\":true,\"firstOrder\":13,\"secondOrder\":1,\"order\":\"13-1\",\"title\":\"Concept\",\"originalName\":\"[13-1]-Concept\"},{\"isOutLine\":true,\"firstOrder\":13,\"secondOrder\":2,\"order\":\"13-2\",\"title\":\"Cartpole\",\"originalName\":\"[13-2]-Cartpole\"}],\"params\":{\"theme\":\"ai\"}}],[\"$\",\"aside\",null,{\"className\":\"hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain\",\"children\":[[\"$\",\"$Ld\",null,{\"href\":\"/ai/[1]-Introduction\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"1\",\". \",\"Introduction\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[2]-Basis-math\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2\",\". \",\"Basis math\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[2-1]-Math-with-RL\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2-1\",\". \",\"Math with RL\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3]-Q-learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3\",\". \",\"Q learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-1]-Basic-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-1\",\". \",\"Basic Concept\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-2]-Greedy-action\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-2\",\". \",\"Greedy action\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-3]-Discount-factor\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-3\",\". \",\"Discount factor\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-4]-Learning-rate\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-4\",\". \",\"Learning rate\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[4]-Markov-process\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"4\",\". \",\"Markov process\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[5]-Bellman-Optimality-Equation\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"5\",\". \",\"Bellman Optimality Equation\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[6]-DP\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"6\",\". \",\"DP\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[7]-Monte-Carlo\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"7\",\". \",\"Monte Carlo\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[8]-Temporal-Difference-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"8\",\". \",\"Temporal Difference Learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[9]-nSTEP-Bootstrapping\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"9\",\". \",\"nSTEP Bootstrapping\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[10]-Planning-and-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10\",\". \",\"Planning and Learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[10-1]-Function-Approximation\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10-1\",\". \",\"Function Approximation\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11]-Deep-learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11\",\". \",\"Deep learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-1]-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-1\",\". \",\"Concept\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-2]-Newerl-Network\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-2\",\". \",\"Newerl Network\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-3]-Loss-function\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-3\",\". \",\"Loss function\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-4]-Activation-function\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-4\",\". \",\"Activation function\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-5]-Gradient-descent\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-5\",\". \",\"Gradient descent\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-6]-Back-Propagation\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-6\",\". \",\"Back Propagation\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[12]-Q-Network\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12\",\". \",\"Q Network\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[12-1]-Frozen-Lake\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12-1\",\". \",\"Frozen Lake\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[12-2]-Cartpole\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12-2\",\". \",\"Cartpole\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[13]-DQN\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13\",\". \",\"DQN\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[13-1]-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13-1\",\". \",\"Concept\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[13-2]-Cartpole\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13-2\",\". \",\"Cartpole\"]}]]}],[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$9\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]}]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"상태 가치 함수 \u0026 행동 가치 함수\",\"className\":\"text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"이 두가지 함수를 한문장으로 요약하면 이겁니다 \",[\"$\",\"strong\",null,{\"children\":\"Expected return\"}],\"을 잘 표현하기 위한 함수입니다.\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"State Value Function: 지금 이 순간, 지금 이 State 로부터 시작해서 기대되는 Return 값\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"현재 state가 주어져 있을때 Return을 계산하는것, 또는 지금 현재 State에 대한 평가(가치)를 내리는거라 볼수도 있습니다.\"}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Action Value Function: 지금 State에서 지금 어떠한 행동으로부터 기대되는 Return\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"이전 Q-learning 시간에서 이동하는 행동에 대해 점수를 매겼늗데. 이것이 Action Value Function 입니다. 즉 Q의 정체입니다.\"}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Optimal Policy: State Value Function 값을 최대화 Policy, 과거는 잊고 지금부터 기대되는 Return을 최대화 하는것, 과거는 지금 시점에서 잘했다 치고 미래를 계산하는것 입니다. 딴예기지만 과거미래현재중 어떤게 중요할까요, 현재부터 잘하자란 예기입니다.\"}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"State Value Function\",\"className\":\"text-3xl font-bold my-5 text-purple-700 hover:text-purple-900 transition-colors duration-200\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"개념은 저게 전부입니다. 이제부턴 수식적으로 이해해보겠습니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Return\"}],\" 의 정의부터 알아보겠습니다.\"]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"G\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"R\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"R\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"R\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"R\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"3\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\".\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\".\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\".\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"munderover\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"k\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∞\"}]]}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"mi\",null,{\"children\":\"k\"}]]}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"R\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"k\"}]]}]]}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"G_t = R_t + R_{t+1} + \\\\gamma R_{t+2} + \\\\gamma^2 R_{t+3} + ... = \\\\sum_{k=0}^{\\\\infty} \\\\gamma^k R_{t+k}\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Expectation을 구하는 공식을 다시한번 기억해 보겠습니다. \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"E\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"E[x]\"}]]}]}]}],\"은 도수(frequency)에 확률을 곱해서 더한것입니다. 다음은 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"x\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"x\"}]]}]}]}],\"에 대한 기대값을 구하는 공식입니다.\"]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"E\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mi\",null,{\"children\":\"X\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}]]}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mi\",null,{\"children\":\"P\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"E[X] = \\\\sum_{x} x P(x)\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"이제 이 \",[\"$\",\"strong\",null,{\"children\":\"Return\"}],\"에 기대값을 취해보겠습니다.\"]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"V\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"munderover\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∞\"}]]}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"G\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"∗\"}],[\"$\",\"mi\",null,{\"children\":\"P\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mo\",null,{\"children\":\"…\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"V_{\\\\pi}(s_t) = \\\\sum_{}^{\\\\infty} G_t * P(a_t, s_{t+1}, a_{t+1}, s_{t+2}, \\\\dots | s_t)\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"해당 공식을 부분적으로 해석해 보겠습니다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"P\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mo\",null,{\"children\":\"…\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"P(a_t, s_{t+1}, a_{t+1}, s_{t+2}, \\\\dots | s_t)\"}]]}]}]}],\": \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"s_t\"}]]}]}]}],\"는 현재 State를 나타냅니다. 현재 State 에서 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"a_t\"}]]}]}]}],\"라는 행동을 했고 이 행동은 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"s_{t+1}\"}]]}]}]}],\"로 이동했습니다. 그리고 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"a_{t+1}\"}]]}]}]}],\"로 행동을 했습니다. \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∞\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\infty\"}]]}]}]}],\" 는 끝까지 같다, 에피소드가 끝났다 라는 뜻입니다.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"G\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"G_t\"}]]}]}]}],\": 현재 State에서 시작해서 끝까지의 Return 값입니다. 위에서 설명한 state아 action들은 전부 random variable 입니다. 그래서 이들의 모든 행동, 어떤 상태에서 이행동도 해보고 저행동도 해보고, 저상태에서 이행동도 해보고 저행동도 해보고.. 할수있는 action, 나올수 있는 state에 대한 모든걸 전부 계산해서 나온 Return에 대한 값 입니다.\"]}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"이 모든것들을 전부 더해서 나온것이 \",[\"$\",\"strong\",null,{\"children\":\"State Value Function\"}],\" 의 값입니다. 이것은 \",[\"$\",\"strong\",null,{\"children\":\"Expected Return\"}],\"이고, 지금부터 미래까지의 Return을 계산한것입니다.\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Action Value Function\",\"className\":\"text-3xl font-bold my-5 text-purple-700 hover:text-purple-900 transition-colors duration-200\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"아까는 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"s_t\"}]]}]}]}],\"에 대한 함수였다면 이번에는 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"s_t, a_t\"}]]}]}]}],\"에 대한 함수입니다. 현재 State에서 어떤 행동을 했을때의 Return 값을 계산하기 위함이기 때문입니다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"Q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"Q\"}]]}]}]}],\"를 앞에다 놨는데 Q-learning에서 배웠던 Q값들의 개념이 바로 이것입니다. Q-learning에서는 이 Q값을 학습하는것이 목표였습니다.\"]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"munderover\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∞\"}]]}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"G\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"∗\"}],[\"$\",\"mi\",null,{\"children\":\"P\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"…\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"Q_{\\\\pi}(s_t, a_t) = \\\\sum_{}^{\\\\infty} G_t * P(s_{t+1}, a_{t+1}, s_{t+2}, a_{t+2} \\\\dots | s_t, a_t)\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"위와 거의 동일합니다. 볼수 있듯이 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"s_t, a_t\"}]]}]}]}],\"에 대한 함수입니다. 위에것은 현재 State에서 진행항것이고, 이것은 현재 State에서 어떤 행동을 했을때 쭉 진행을 해본 기댓값 입니다.\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"ref: \",[\"$\",\"a\",null,{\"href\":\"https://ai-sinq.tistory.com/entry/Bellman-Equation%EB%B2%A8%EB%A7%8C-%EB%B0%A9%EC%A0%95%EC%8B%9D\",\"children\":\"https://ai-sinq.tistory.com/entry/Bellman-Equation%EB%B2%A8%EB%A7%8C-%EB%B0%A9%EC%A0%95%EC%8B%9D\"}]]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"벨만 방정식(Bellman Equation)\",\"className\":\"text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"벨만 방정식을 요약하면 다음과 같습니다. \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"V\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"V_{\\\\pi}(s_t)\"}]]}]}]}],\" 를 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"Q_{\\\\pi}(s_t, a_t)\"}]]}]}]}],\" 로 표현하는것, 혹은 그 반대, 아니면 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"V\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"V_{\\\\pi}(s_t)\"}]]}]}]}],\"를 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"V\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"V_{\\\\pi}(s_{t+1})\"}]]}]}]}],\"로 표현하는것, 혹은 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"Q_{\\\\pi}(s_t, a_t)\"}]]}]}]}],\"를 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"Q_{\\\\pi}(s_{t+1}, a_{t+1})\"}]]}]}]}],\"로 표현하는것입니다. 이것이 바로 벨만 방정식에 대한 간단한 요약 입니다.\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"V\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"V_{\\\\pi}(s_t)\"}]]}]}]}],\" to \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"Q_{\\\\pi}(s_t, a_t)\"}]]}]}]}]],\"className\":\"text-3xl font-bold my-5 text-purple-700 hover:text-purple-900 transition-colors duration-200\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TODO: 모라는거야\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"v\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"children\":\"∈\"}],[\"$\",\"mi\",null,{\"children\":\"A\"}]]}]]}],[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mi\",null,{\"children\":\"π\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"v_\\\\pi(s) = \\\\sum_{a \\\\in A} \\\\pi(a|s) q_\\\\pi(s, a)\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이전 Q-learning를 예로들어 설명해보면, 한 격자에 Q값이 상하좌우 4개 있었죠? 그 값들의 평균치가 그 상태, 그 격자에서부터 기대되는 기댓값, 그 상태에서부터 기대되는 기대값이 되는겁니다.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Optimal Policy\",\"className\":\"text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"정책\",\"className\":\"text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"지금까지 정책을 많이 있는것처럼 말했지만 입입실론-Greedy 정책의, 결정적 정책과 확률적 정책이 전부라고 할수 있다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이중ㅇ서 greedy 정책을의외로 많이 쓴데, 대부분\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"결정적 정책에서 argmax(qx...) 를 보면 지금까지 저누 배웠지만 q를 모른다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"즉 q를 학습하는것이 최적의 정책을 학습하는거다??? 이 줄은 애매하다..\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Gt(액센 벨류 펑션) Gt + 1 는 다르다. Gt + 1 을 Gt(액션 벨류 펑션션 으로 바꿔줘야 한다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"정책에 대해 오해해할수 이는는게 정책은 어디까지나 탐험험이고 자의적으로 끝날수 있는게 아님, 탐험이 끝났다면 선택 정책으로? 바꿔야함\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"최적\",\"className\":\"text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이론적으로 존재하는 최적 상태 즉 참인상태로 실제로 우리가 알수 있는건 아님, 이 최적 상태를 이론적으로 알기 위해 학습을 하는거기도 함\"}]]}]}]\n"])</script></body></html>