몬테카를로와 시간차 학습의 방법을 통합한것, 간단히

# 표본추출

먼저 표본추출일ㄴ것을 아아야한다. 대한민국의 평균키를 구하려면? 대한민국의 모든 사람들을 키를 재면 됌, 근데 불가능임

또는 우연히 10명을 뽑았는데 190인 사람이다? 이것도 아니지

표본추출을 많이 하면 더 뾰족해져서 몬갈 딱 하나 골랐을때 남자키 173이 나올 확률이나온다는것임, 많으면 많을수록 좁아짐

컴퓨터를 이용해 어떠한 수학 문제를 푼다는건, 기본적으로 예측 한다는 거라네요

***

# n-Step
바로 다음 스탭이 아니라 2스탭, 3스탭, n스탭 보면 더 가치함수를 정확하게 추정하지 않을까? 라는 아이디어임

근데 n스탭이 늘어나면Terminated까지 가서 몬테카를로가 됌?

그래서 결국 TD와 몬테카를로둘다 설명 가능함, 자연스럽게 몬테카를로에서 사용했던 잡깃ㄹ도 사용 가능함

## n-Step TD Prediction
(St) 를 업데이트 하려면 Rt + 1, Rt+ 2, Rt + 3을 가져야함, 이러면 이제 St0가 업데이트됌, 중요한건 실제 있는 상태는 St3이지만 실제 업데이트 돼는건 St0라는 과거가 업데이트 됀다..

그리고 이렇게 과거친구를 업데이트할건데 이러한 과거 친구를 타워?타우? 라고 부를거다.

굳이 이렇게 말하는건 보통t는 현재시점인데, t를 업데이트 하기ㅣ 위해 미래값으로 업데이트? 말이 안돼서..

그리고 이걸 고려할때, 미래값이 없어서 좀 미루고 해야함?

그리고 또하나 고려해야할건 만약 끝까지 가서 n이 2개밖에, 관측할수 있는 보상이 2개밖에 없다 글때도 고려해야함,

그리고 termistaed보다 어쩌구가 더 ㅓ지면, 리워드가 없으니 그 전까지 끊어버리고.. 어쩌구 저적.. 코드설명임

근데 딱히 termistat가 없어도됌, 없어도 돼서 이렇게 조건을 거는거라 한다.

***

# nStep sarsa
nStep Q-learning는 설왕설레가 많다고 한다..

**다이어그램**: 검정색으로 쓰는 이유는, 살사같은건 처음에 S,a가 있다 가정한다 그러네

***

# n-Step Off-policy w.o / Importance Sampling
