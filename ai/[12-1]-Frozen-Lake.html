<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes"/><link rel="preload" href="/_next/static/media/7626ed2c039b2726-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="./img/Q-network-FrozenLake.png"/><link rel="stylesheet" href="/_next/static/css/d861847f33112ff5.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/dd89e605550f760e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-8fd1466900fdaeb8.js"/><script src="/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/_next/static/chunks/23-a9892337a8234d4f.js" async=""></script><script src="/_next/static/chunks/main-app-ce18d4723c8629f4.js" async=""></script><script src="/_next/static/chunks/578c2090-c1b891f3b6c746fd.js" async=""></script><script src="/_next/static/chunks/b563f954-758761ebc4ecc2e7.js" async=""></script><script src="/_next/static/chunks/8e1d74a4-44e18cb83de8b273.js" async=""></script><script src="/_next/static/chunks/0e762574-0fedad6633d82a8a.js" async=""></script><script src="/_next/static/chunks/231-87925b9c7247c60f.js" async=""></script><script src="/_next/static/chunks/app/%5Btheme%5D/layout-352a59871d9d7543.js" async=""></script><title>tomatom4to&#x27;s Computer Science Blog</title><meta name="description" content="Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples."/><meta name="author" content="tomatom4to"/><meta name="keywords" content="Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development"/><meta name="creator" content="tomatom4to"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://tomatom4to.github.io"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta property="og:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><meta property="og:url" content="https://tomatom4to.github.io"/><meta property="og:site_name" content="tomatom4to&#x27;s CS Blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta name="twitter:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><link rel="icon" href="/icon.ico?3c4912ce8b26c1d6" type="image/x-icon" sizes="256x256"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_9b822d min-h-screen bg-slate-50 text-blue-950"><div class="grid grid-cols-[24rem_1fr] auto-rows-auto"><nav class="__className_92d895 bg-slate-50 w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed"><a href="/">tomatoM4to&#x27;s blog</a><div class="hidden lg:flex items-center"><input type="text" class="w-36 h-7 rounded-full border-2 border-black pl-2" placeholder="search"/><div class="bg-slate-300 h-10 w-0.5 ml-2"></div><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button></div></nav><main class="col-span-2"><div class="flex"><aside class="lg:hidden"><button class=" flex flex-col gap-1 justify-center items-center w-10 h-10 rounded-lg fixed right-2 top-2 active:outline-none p-2 hover:bg-gray-200 transition-all" style="z-index:15"><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span><span class="w-6 h-0.5 bg-black rounded transition-opacity duration-300 ease-in-out opacity-100"></span><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span></button><div class="
                bg-slate-50
                fixed
                top-0
                right-0
                flex
                flex-col
                px-5
                h-full
                w-7/12
                shadow-lg
                transform
                transition-transform
                duration-300
                ease-in-out
                translate-x-full
                " style="z-index:10"><nav class="h-14 flex items-center border-b-2"><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"></path></svg></button></nav><div class="pb-5 flex flex-col overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-Introduction">1<!-- -->. <!-- -->Introduction</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-1]-Basic-Concept">3-1<!-- -->. <!-- -->Basic Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-2]-Greedy-action">3-2<!-- -->. <!-- -->Greedy action</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-3]-Discount-factor">3-3<!-- -->. <!-- -->Discount factor</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-4]-Learning-rate">3-4<!-- -->. <!-- -->Learning rate</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning">11<!-- -->. <!-- -->Deep learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Concept">11-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-2]-Newerl-Network">11-2<!-- -->. <!-- -->Newerl Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-3]-Loss-function">11-3<!-- -->. <!-- -->Loss function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-4]-Activation-function">11-4<!-- -->. <!-- -->Activation function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-5]-Gradient-descent">11-5<!-- -->. <!-- -->Gradient descent</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-6]-Back-Propagation">11-6<!-- -->. <!-- -->Back Propagation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12]-Q-Network">12<!-- -->. <!-- -->Q Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-1]-Frozen-Lake">12-1<!-- -->. <!-- -->Frozen Lake</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-2]-Cartpole">12-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13]-DQN">13<!-- -->. <!-- -->DQN</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-1]-Concept">13-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-2]-Cartpole">13-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[14]-Policy-gradient">14<!-- -->. <!-- -->Policy gradient</a></div></div><div class="
        w-screen
        h-screen
        bg-white
        blur-lg
        fixed
        left-0
        top-0
        transition-opacity
        duration-300
        opacity-0 pointer-events-none" style="z-index:5"></div></aside><aside class="hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-Introduction">1<!-- -->. <!-- -->Introduction</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-1]-Basic-Concept">3-1<!-- -->. <!-- -->Basic Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-2]-Greedy-action">3-2<!-- -->. <!-- -->Greedy action</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-3]-Discount-factor">3-3<!-- -->. <!-- -->Discount factor</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-4]-Learning-rate">3-4<!-- -->. <!-- -->Learning rate</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning">11<!-- -->. <!-- -->Deep learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Concept">11-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-2]-Newerl-Network">11-2<!-- -->. <!-- -->Newerl Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-3]-Loss-function">11-3<!-- -->. <!-- -->Loss function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-4]-Activation-function">11-4<!-- -->. <!-- -->Activation function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-5]-Gradient-descent">11-5<!-- -->. <!-- -->Gradient descent</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-6]-Back-Propagation">11-6<!-- -->. <!-- -->Back Propagation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12]-Q-Network">12<!-- -->. <!-- -->Q Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-1]-Frozen-Lake">12-1<!-- -->. <!-- -->Frozen Lake</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-2]-Cartpole">12-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13]-DQN">13<!-- -->. <!-- -->DQN</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-1]-Concept">13-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-2]-Cartpole">13-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[14]-Policy-gradient">14<!-- -->. <!-- -->Policy gradient</a></aside><div class="lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden"><div class="w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body"><p><a href="https://dryjelly.tistory.com/138">https://dryjelly.tistory.com/138</a></p>
<h1 class=" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">소개</h1>
<p>이전에 공부했던 Q-network를 Frozen Lake에 적용해 보겠습니다. 하지만 여러분들도 알다 싶이 Frozen Lake는 굉장히 쉬운 문제입니다. 이 문제를 해결하기 위해 NN을 적용한다는것은 마치 사과를 깎기 위해 팔뚝만한 중식도를 사용하는것과 같습니다. 그저 이해를 돕기 위한 코드란 점을 감안해 주세요.</p>
<p>코드응 pytorch 를 사용합니다.</p>
<p>전체 코드</p>
<pre class="overflow-x-auto bg-gray-200 rounded-lg "><code class="overflow-x-auto bg-slate-300 px-1 rounded-md hljs language-python"><span class="hljs-keyword">import</span> gymnasium <span class="hljs-keyword">as</span> gym
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-keyword">class</span> <span class="hljs-title class_">QNetwork</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, output_size</span>):
        <span class="hljs-built_in">super</span>(QNetwork, <span class="hljs-variable language_">self</span>).__init__()
        <span class="hljs-variable language_">self</span>.layer1 = nn.Linear(input_size, output_size)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):
        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.layer1(x)

<span class="hljs-keyword">class</span> <span class="hljs-title class_">DQNAgent</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, output_size, learning_rate=<span class="hljs-number">0.1</span>, gamma=<span class="hljs-number">0.99</span></span>):
        <span class="hljs-variable language_">self</span>.device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)
        <span class="hljs-variable language_">self</span>.q_network = QNetwork(input_size, output_size).to(<span class="hljs-variable language_">self</span>.device)
        <span class="hljs-variable language_">self</span>.optimizer = optim.SGD(<span class="hljs-variable language_">self</span>.q_network.parameters(), lr=learning_rate)
        <span class="hljs-variable language_">self</span>.gamma = gamma

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_action</span>(<span class="hljs-params">self, state, epsilon</span>):
        <span class="hljs-keyword">with</span> torch.no_grad():
            state_tensor = state.to(<span class="hljs-variable language_">self</span>.device)
            q_values = <span class="hljs-variable language_">self</span>.q_network(state_tensor.unsqueeze(<span class="hljs-number">0</span>))  <span class="hljs-comment"># Batch 추가</span>
            <span class="hljs-keyword">if</span> np.random.random() &lt; epsilon:
                <span class="hljs-keyword">return</span> np.random.randint(q_values.size(-<span class="hljs-number">1</span>))
            <span class="hljs-keyword">return</span> q_values.argmax().item()

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_step</span>(<span class="hljs-params">self, state, action, reward, next_state, done</span>):
        state_tensor = state.to(<span class="hljs-variable language_">self</span>.device)
        next_state_tensor = next_state.to(<span class="hljs-variable language_">self</span>.device)

        <span class="hljs-comment"># 현재 Q 값 계산</span>
        current_q_values = <span class="hljs-variable language_">self</span>.q_network(state_tensor.unsqueeze(<span class="hljs-number">0</span>))  <span class="hljs-comment"># Batch 추가</span>
        q_value = current_q_values[<span class="hljs-number">0</span>, action].unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 차원 추가</span>

        <span class="hljs-comment"># 타겟 Q 값 계산</span>
        <span class="hljs-keyword">with</span> torch.no_grad():
            next_q_values = <span class="hljs-variable language_">self</span>.q_network(next_state_tensor.unsqueeze(<span class="hljs-number">0</span>))  <span class="hljs-comment"># Batch 추가</span>
            max_next_q = next_q_values.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]
            target = torch.tensor([reward + (<span class="hljs-number">1</span> - done) * <span class="hljs-variable language_">self</span>.gamma * max_next_q], device=<span class="hljs-variable language_">self</span>. device)  <span class="hljs-comment"># 크기 맞추기</span>

        <span class="hljs-comment"># 손실 계산 및 최적화</span>
        <span class="hljs-variable language_">self</span>.optimizer.zero_grad()
        loss = nn.MSELoss()(q_value, target)
        loss.backward()
        <span class="hljs-variable language_">self</span>.optimizer.step()

        <span class="hljs-keyword">return</span> loss.item()

<span class="hljs-string">&#x27;&#x27;&#x27;
Converts an state (int) to a tensor representation.
For example, the FrozenLake 4x4 map has 4x4=16 states numbered from 0 to 15.
Parameters: state=1, num_states=16
Return: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
&#x27;&#x27;&#x27;</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">one_hot</span>(<span class="hljs-params">state: <span class="hljs-built_in">int</span>, num_states: <span class="hljs-built_in">int</span></span>) -&gt; torch.Tensor:
    input_tensor = torch.zeros(num_states)
    input_tensor[state] = <span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> input_tensor

<span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():
    env = gym.make(<span class="hljs-string">&#x27;FrozenLake-v1&#x27;</span>, is_slippery=<span class="hljs-literal">False</span>)
    input_size = env.observation_space.n
    output_size = env.action_space.n
    num_episodes = <span class="hljs-number">500</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;input_size: <span class="hljs-subst">{input_size}</span>, output_size: <span class="hljs-subst">{output_size}</span>&quot;</span>)
    agent = DQNAgent(input_size, output_size)
    rewards_history = []

    <span class="hljs-keyword">for</span> episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_episodes):
        state = env.reset()[<span class="hljs-number">0</span>]
        state = one_hot(state, input_size)

        epsilon = <span class="hljs-number">1.0</span> / ((episode / <span class="hljs-number">50</span>) + <span class="hljs-number">10</span>)
        episode_reward = <span class="hljs-number">0</span>
        done = <span class="hljs-literal">False</span>

        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:
            action = agent.get_action(state, epsilon)
            next_state, reward, done, _, _ = env.step(action)
            next_state = one_hot(next_state, input_size)

            loss = agent.train_step(state, action, reward, next_state, done)
            episode_reward += reward
            state = next_state

        rewards_history.append(episode_reward)

    <span class="hljs-keyword">return</span> rewards_history

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:
    rewards_history = train()
    success_rate = <span class="hljs-built_in">sum</span>(rewards_history) / <span class="hljs-built_in">len</span>(rewards_history) * <span class="hljs-number">100</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Success rate: <span class="hljs-subst">{success_rate:<span class="hljs-number">.2</span>f}</span>%&quot;</span>)

    plt.bar(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rewards_history)), rewards_history, color=<span class="hljs-string">&quot;blue&quot;</span>)
    plt.xlabel(<span class="hljs-string">&quot;Episode&quot;</span>)
    plt.ylabel(<span class="hljs-string">&quot;Reward&quot;</span>)
    plt.title(<span class="hljs-string">&quot;Rewards per Episode&quot;</span>)
    plt.savefig(<span class="hljs-string">&quot;Q-network-FrozenLake.png&quot;</span>)
</code></pre>
<p><strong>OUTPUT</strong>
<img src="./img/Q-network-FrozenLake.png" alt="Q-network FrozenLake"/></p>
<hr/>
<p>질문 리스트</p>
<ol class="list-decimal ml-12 space-y-2 my-3">
<li>원핫 인코딩의 장점?</li>
<li>FrozenLake는 2차원 평면에서 이루어지는 게임이지만 해당 코드는 플레이어만 1로 표현하게 되는데, 결과가 나쁘지 않다, 이는 고정된 맵이기 때문에 특정 지역에 가면 안된다는것을 선형레이어로만으로도 학습이 되기 때문인가?</li>
<li>콘볼루션 레이어는 2차원 데이터를 파악하기 쉬운 레이어라고 알고 있는데, 이때 input에 해당하는 데이터는 굳이 RGB, 흑백 이미지 데이터가 아니라 임의적으로 선언한 1부터 N까지 숫자를 매핑해줘도 될까?</li>
<li>만약 된다면 1부터 N까지의 정수가 아닌 0.0부터 1.0까지의 숫자로 매핑해주는게 더 좋다는데 맞나?</li>
<li>2번 과제에서 멀티프레임을 적용시켰는데, 이를 사용한 근거는 단일 프레임으론 Agent의 움직임을 파악하기 힘들거 같아서 2프레림의 데이터를 중첩시켜서 사용했다, Atari 게임 논문에서도 4Frame의 데이터를 사용했는데 이는 Agent과 환경의 움직임을 파악하기 위함이라 해석했는데 그냥 단일 프레임으로 하면 시간이 너무 오래걸려선가?</li>
<li>카트폴 문제에선 환경에 대한 정보 없이 오로지 Agent의 데이터로만 학습을 진행했다(각도, 속도). 이는  외부 환경이 변하지 않기 때문이라 그런거 같은데, 환경이 변화하는 게임에서도 이러한 방식으로 학습을 진행할 수 있을까? 예를들어 꿀벌들의 위치, 말벌들의 위치, 내 위치, 내 방향 등등을 콘볼루션이 아닌 선형 레이어에 넣어서 학습을 진행한다면?</li>
<li>보상을 과도하게 준다면 학습이 빠르게 진행되지만 안정성이 떨어지고, 너무 적게준다면 학습이 느리게 진행되고, 너무 복잡하게 줘도 학습이 안될수도 있고.. 최대한 심플하게 줘야 하는건가?</li>
<li>보상이 너무 커서 불안정해 지는걸 막기 위해 <code class="overflow-x-auto bg-slate-300 px-1 rounded-md ">torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0) # 클리핑</code> 이런식으로 클리핑 시켰는데 이러면 이제 안정성을 확보하면서 학습을 빠르게 징행할수 있을까?</li>
</ol></div></div></div></main></div><script src="/_next/static/chunks/webpack-8fd1466900fdaeb8.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/7626ed2c039b2726-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/css/d861847f33112ff5.css\",\"style\"]\n4:HL[\"/_next/static/css/dd89e605550f760e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"5:I[5751,[],\"\"]\n8:I[9275,[],\"\"]\nb:I[1343,[],\"\"]\nd:I[231,[\"217\",\"static/chunks/578c2090-c1b891f3b6c746fd.js\",\"675\",\"static/chunks/b563f954-758761ebc4ecc2e7.js\",\"699\",\"static/chunks/8e1d74a4-44e18cb83de8b273.js\",\"779\",\"static/chunks/0e762574-0fedad6633d82a8a.js\",\"231\",\"static/chunks/231-87925b9c7247c60f.js\",\"575\",\"static/chunks/app/%5Btheme%5D/layout-352a59871d9d7543.js\"],\"\"]\nf:I[6130,[],\"\"]\n9:[\"theme\",\"ai\",\"d\"]\na:[\"post\",\"%5B12-1%5D-Frozen-Lake\",\"d\"]\n10:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d861847f33112ff5.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"oXnQ0BEsHmbp-_2zvqdng\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/%5B12-1%5D-Frozen-Lake\",\"initialTree\":[\"\",{\"children\":[[\"theme\",\"ai\",\"d\"],{\"children\":[[\"post\",\"%5B12-1%5D-Frozen-Lake\",\"d\"],{\"children\":[\"__PAGE__?{\\\"theme\\\":\\\"ai\\\",\\\"post\\\":\\\"[12-1]-Frozen-Lake\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"theme\",\"ai\",\"d\"],{\"children\":[[\"post\",\"%5B12-1%5D-Frozen-Lake\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L6\",\"$L7\"],null],null]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$9\",\"children\",\"$a\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/dd89e605550f760e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],null]},[\"$Lc\",null],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_9b822d min-h-screen bg-slate-50 text-blue-950\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-[24rem_1fr] auto-rows-auto\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"__className_92d895 bg-slate-50 w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed\",\"children\":[[\"$\",\"$Ld\",null,{\"href\":\"/\",\"children\":\"tomatoM4to's blog\"}],[\"$\",\"div\",null,{\"className\":\"hidden lg:flex items-center\",\"children\":[[\"$\",\"input\",null,{\"type\":\"text\",\"className\":\"w-36 h-7 rounded-full border-2 border-black pl-2\",\"placeholder\":\"search\"}],[\"$\",\"div\",null,{\"className\":\"bg-slate-300 h-10 w-0.5 ml-2\"}],[\"$\",\"$Ld\",null,{\"href\":\"https://github.com/tomatoM4to/tomatoM4to.github.io\",\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 24 24\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fill\":\"none\",\"strokeWidth\":\"2\",\"d\":\"M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278\",\"children\":[]}],[\"$\",\"path\",\"1\",{\"d\":\"M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]]}]]}],[\"$\",\"main\",null,{\"className\":\"col-span-2\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$Le\"],\"globalErrorComponent\":\"$f\",\"missingSlots\":\"$W10\"}]]\n"])</script><script>self.__next_f.push([1,"11:I[1815,[\"217\",\"static/chunks/578c2090-c1b891f3b6c746fd.js\",\"675\",\"static/chunks/b563f954-758761ebc4ecc2e7.js\",\"699\",\"static/chunks/8e1d74a4-44e18cb83de8b273.js\",\"779\",\"static/chunks/0e762574-0fedad6633d82a8a.js\",\"231\",\"static/chunks/231-87925b9c7247c60f.js\",\"575\",\"static/chunks/app/%5Btheme%5D/layout-352a59871d9d7543.js\"],\"Hamburger\"]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"10\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:title\",\"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:url\",\"content\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:site_name\",\"content\":\"tomatom4to's CS Blog\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:title\",\"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/icon.ico?3c4912ce8b26c1d6\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"6:null\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"div\",null,{\"className\":\"flex\",\"children\":[[\"$\",\"$L11\",null,{\"res\":[{\"isOutLine\":false,\"firstOrder\":1,\"secondOrder\":-1,\"order\":\"1\",\"title\":\"Introduction\",\"originalName\":\"[1]-Introduction\"},{\"isOutLine\":false,\"firstOrder\":2,\"secondOrder\":-1,\"order\":\"2\",\"title\":\"Basis math\",\"originalName\":\"[2]-Basis-math\"},{\"isOutLine\":true,\"firstOrder\":2,\"secondOrder\":1,\"order\":\"2-1\",\"title\":\"Math with RL\",\"originalName\":\"[2-1]-Math-with-RL\"},{\"isOutLine\":false,\"firstOrder\":3,\"secondOrder\":-1,\"order\":\"3\",\"title\":\"Q learning\",\"originalName\":\"[3]-Q-learning\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":1,\"order\":\"3-1\",\"title\":\"Basic Concept\",\"originalName\":\"[3-1]-Basic-Concept\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":2,\"order\":\"3-2\",\"title\":\"Greedy action\",\"originalName\":\"[3-2]-Greedy-action\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":3,\"order\":\"3-3\",\"title\":\"Discount factor\",\"originalName\":\"[3-3]-Discount-factor\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":4,\"order\":\"3-4\",\"title\":\"Learning rate\",\"originalName\":\"[3-4]-Learning-rate\"},{\"isOutLine\":false,\"firstOrder\":4,\"secondOrder\":-1,\"order\":\"4\",\"title\":\"Markov process\",\"originalName\":\"[4]-Markov-process\"},{\"isOutLine\":false,\"firstOrder\":5,\"secondOrder\":-1,\"order\":\"5\",\"title\":\"Bellman Optimality Equation\",\"originalName\":\"[5]-Bellman-Optimality-Equation\"},{\"isOutLine\":false,\"firstOrder\":6,\"secondOrder\":-1,\"order\":\"6\",\"title\":\"DP\",\"originalName\":\"[6]-DP\"},{\"isOutLine\":false,\"firstOrder\":7,\"secondOrder\":-1,\"order\":\"7\",\"title\":\"Monte Carlo\",\"originalName\":\"[7]-Monte-Carlo\"},{\"isOutLine\":false,\"firstOrder\":8,\"secondOrder\":-1,\"order\":\"8\",\"title\":\"Temporal Difference Learning\",\"originalName\":\"[8]-Temporal-Difference-Learning\"},{\"isOutLine\":false,\"firstOrder\":9,\"secondOrder\":-1,\"order\":\"9\",\"title\":\"nSTEP Bootstrapping\",\"originalName\":\"[9]-nSTEP-Bootstrapping\"},{\"isOutLine\":false,\"firstOrder\":10,\"secondOrder\":-1,\"order\":\"10\",\"title\":\"Planning and Learning\",\"originalName\":\"[10]-Planning-and-Learning\"},{\"isOutLine\":true,\"firstOrder\":10,\"secondOrder\":1,\"order\":\"10-1\",\"title\":\"Function Approximation\",\"originalName\":\"[10-1]-Function-Approximation\"},{\"isOutLine\":false,\"firstOrder\":11,\"secondOrder\":-1,\"order\":\"11\",\"title\":\"Deep learning\",\"originalName\":\"[11]-Deep-learning\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":1,\"order\":\"11-1\",\"title\":\"Concept\",\"originalName\":\"[11-1]-Concept\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":2,\"order\":\"11-2\",\"title\":\"Newerl Network\",\"originalName\":\"[11-2]-Newerl-Network\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":3,\"order\":\"11-3\",\"title\":\"Loss function\",\"originalName\":\"[11-3]-Loss-function\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":4,\"order\":\"11-4\",\"title\":\"Activation function\",\"originalName\":\"[11-4]-Activation-function\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":5,\"order\":\"11-5\",\"title\":\"Gradient descent\",\"originalName\":\"[11-5]-Gradient-descent\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":6,\"order\":\"11-6\",\"title\":\"Back Propagation\",\"originalName\":\"[11-6]-Back-Propagation\"},{\"isOutLine\":false,\"firstOrder\":12,\"secondOrder\":-1,\"order\":\"12\",\"title\":\"Q Network\",\"originalName\":\"[12]-Q-Network\"},{\"isOutLine\":true,\"firstOrder\":12,\"secondOrder\":1,\"order\":\"12-1\",\"title\":\"Frozen Lake\",\"originalName\":\"[12-1]-Frozen-Lake\"},{\"isOutLine\":true,\"firstOrder\":12,\"secondOrder\":2,\"order\":\"12-2\",\"title\":\"Cartpole\",\"originalName\":\"[12-2]-Cartpole\"},{\"isOutLine\":false,\"firstOrder\":13,\"secondOrder\":-1,\"order\":\"13\",\"title\":\"DQN\",\"originalName\":\"[13]-DQN\"},{\"isOutLine\":true,\"firstOrder\":13,\"secondOrder\":1,\"order\":\"13-1\",\"title\":\"Concept\",\"originalName\":\"[13-1]-Concept\"},{\"isOutLine\":true,\"firstOrder\":13,\"secondOrder\":2,\"order\":\"13-2\",\"title\":\"Cartpole\",\"originalName\":\"[13-2]-Cartpole\"},{\"isOutLine\":false,\"firstOrder\":14,\"secondOrder\":-1,\"order\":\"14\",\"title\":\"Policy gradient\",\"originalName\":\"[14]-Policy-gradient\"}],\"params\":{\"theme\":\"ai\"}}],[\"$\",\"aside\",null,{\"className\":\"hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain\",\"children\":[[\"$\",\"$Ld\",null,{\"href\":\"/ai/[1]-Introduction\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"1\",\". \",\"Introduction\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[2]-Basis-math\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2\",\". \",\"Basis math\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[2-1]-Math-with-RL\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2-1\",\". \",\"Math with RL\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3]-Q-learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3\",\". \",\"Q learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-1]-Basic-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-1\",\". \",\"Basic Concept\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-2]-Greedy-action\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-2\",\". \",\"Greedy action\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-3]-Discount-factor\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-3\",\". \",\"Discount factor\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[3-4]-Learning-rate\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-4\",\". \",\"Learning rate\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[4]-Markov-process\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"4\",\". \",\"Markov process\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[5]-Bellman-Optimality-Equation\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"5\",\". \",\"Bellman Optimality Equation\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[6]-DP\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"6\",\". \",\"DP\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[7]-Monte-Carlo\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"7\",\". \",\"Monte Carlo\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[8]-Temporal-Difference-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"8\",\". \",\"Temporal Difference Learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[9]-nSTEP-Bootstrapping\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"9\",\". \",\"nSTEP Bootstrapping\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[10]-Planning-and-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10\",\". \",\"Planning and Learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[10-1]-Function-Approximation\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10-1\",\". \",\"Function Approximation\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11]-Deep-learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11\",\". \",\"Deep learning\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-1]-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-1\",\". \",\"Concept\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-2]-Newerl-Network\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-2\",\". \",\"Newerl Network\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-3]-Loss-function\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-3\",\". \",\"Loss function\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-4]-Activation-function\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-4\",\". \",\"Activation function\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-5]-Gradient-descent\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-5\",\". \",\"Gradient descent\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[11-6]-Back-Propagation\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-6\",\". \",\"Back Propagation\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[12]-Q-Network\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12\",\". \",\"Q Network\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[12-1]-Frozen-Lake\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12-1\",\". \",\"Frozen Lake\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[12-2]-Cartpole\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12-2\",\". \",\"Cartpole\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[13]-DQN\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13\",\". \",\"DQN\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[13-1]-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13-1\",\". \",\"Concept\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[13-2]-Cartpole\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13-2\",\". \",\"Cartpole\"]}],[\"$\",\"$Ld\",null,{\"href\":\"/ai/[14]-Policy-gradient\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"14\",\". \",\"Policy gradient\"]}]]}],[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$9\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lb\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]}]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://dryjelly.tistory.com/138\",\"children\":\"https://dryjelly.tistory.com/138\"}]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"소개\",\"className\":\" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이전에 공부했던 Q-network를 Frozen Lake에 적용해 보겠습니다. 하지만 여러분들도 알다 싶이 Frozen Lake는 굉장히 쉬운 문제입니다. 이 문제를 해결하기 위해 NN을 적용한다는것은 마치 사과를 깎기 위해 팔뚝만한 중식도를 사용하는것과 같습니다. 그저 이해를 돕기 위한 코드란 점을 감안해 주세요.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"코드응 pytorch 를 사용합니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"전체 코드\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"className\":\"overflow-x-auto bg-slate-300 px-1 rounded-md hljs language-python\",\"children\":[[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" gymnasium \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"as\"}],\" gym\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" numpy \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"as\"}],\" np\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" torch\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" torch.nn \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"as\"}],\" nn\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" torch.optim \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"as\"}],\" optim\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" matplotlib.pyplot \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"as\"}],\" plt\\n\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"class\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title class_\",\"children\":\"QNetwork\"}],\"(nn.Module):\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title function_\",\"children\":\"__init__\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-params\",\"children\":\"self, input_size, output_size\"}],\"):\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"super\"}],\"(QNetwork, \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\").__init__()\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".layer1 = nn.Linear(input_size, output_size)\\n\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title function_\",\"children\":\"forward\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-params\",\"children\":\"self, x\"}],\"):\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".layer1(x)\\n\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"class\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title class_\",\"children\":\"DQNAgent\"}],\":\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title function_\",\"children\":\"__init__\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-params\",\"children\":[\"self, input_size, output_size, learning_rate=\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0.1\"}],\", gamma=\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0.99\"}]]}],\"):\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".device = torch.device(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"cuda\\\"\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"if\"}],\" torch.cuda.is_available() \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"else\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"cpu\\\"\"}],\")\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".q_network = QNetwork(input_size, output_size).to(\",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".device)\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".optimizer = optim.SGD(\",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".q_network.parameters(), lr=learning_rate)\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".gamma = gamma\\n\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title function_\",\"children\":\"get_action\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-params\",\"children\":\"self, state, epsilon\"}],\"):\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"with\"}],\" torch.no_grad():\\n            state_tensor = state.to(\",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".device)\\n            q_values = \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".q_network(state_tensor.unsqueeze(\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\"))  \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# Batch 추가\"}],\"\\n            \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"if\"}],\" np.random.random() \u003c epsilon:\\n                \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" np.random.randint(q_values.size(-\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"1\"}],\"))\\n            \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" q_values.argmax().item()\\n\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title function_\",\"children\":\"train_step\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-params\",\"children\":\"self, state, action, reward, next_state, done\"}],\"):\\n        state_tensor = state.to(\",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".device)\\n        next_state_tensor = next_state.to(\",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".device)\\n\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# 현재 Q 값 계산\"}],\"\\n        current_q_values = \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".q_network(state_tensor.unsqueeze(\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\"))  \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# Batch 추가\"}],\"\\n        q_value = current_q_values[\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\", action].unsqueeze(\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\")  \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# 차원 추가\"}],\"\\n\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# 타겟 Q 값 계산\"}],\"\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"with\"}],\" torch.no_grad():\\n            next_q_values = \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".q_network(next_state_tensor.unsqueeze(\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\"))  \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# Batch 추가\"}],\"\\n            max_next_q = next_q_values.\",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"max\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"1\"}],\")[\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\"]\\n            target = torch.tensor([reward + (\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"1\"}],\" - done) * \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".gamma * max_next_q], device=\",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\". device)  \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# 크기 맞추기\"}],\"\\n\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-comment\",\"children\":\"# 손실 계산 및 최적화\"}],\"\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".optimizer.zero_grad()\\n        loss = nn.MSELoss()(q_value, target)\\n        loss.backward()\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-variable language_\",\"children\":\"self\"}],\".optimizer.step()\\n\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" loss.item()\\n\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"'''\\nConverts an state (int) to a tensor representation.\\nFor example, the FrozenLake 4x4 map has 4x4=16 states numbered from 0 to 15.\\nParameters: state=1, num_states=16\\nReturn: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\\n'''\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title function_\",\"children\":\"one_hot\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-params\",\"children\":[\"state: \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"int\"}],\", num_states: \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"int\"}]]}],\") -\u003e torch.Tensor:\\n    input_tensor = torch.zeros(num_states)\\n    input_tensor[state] = \",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"1\"}],\"\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" input_tensor\\n\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-title function_\",\"children\":\"train\"}],\"():\\n    env = gym.make(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"'FrozenLake-v1'\"}],\", is_slippery=\",[\"$\",\"span\",null,{\"className\":\"hljs-literal\",\"children\":\"False\"}],\")\\n    input_size = env.observation_space.n\\n    output_size = env.action_space.n\\n    num_episodes = \",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"500\"}],\"\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"print\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":[\"f\\\"input_size: \",[\"$\",\"span\",null,{\"className\":\"hljs-subst\",\"children\":\"{input_size}\"}],\", output_size: \",[\"$\",\"span\",null,{\"className\":\"hljs-subst\",\"children\":\"{output_size}\"}],\"\\\"\"]}],\")\\n    agent = DQNAgent(input_size, output_size)\\n    rewards_history = []\\n\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"for\"}],\" episode \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"in\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"range\"}],\"(num_episodes):\\n        state = env.reset()[\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\"]\\n        state = one_hot(state, input_size)\\n\\n        epsilon = \",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"1.0\"}],\" / ((episode / \",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"50\"}],\") + \",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"10\"}],\")\\n        episode_reward = \",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"0\"}],\"\\n        done = \",[\"$\",\"span\",null,{\"className\":\"hljs-literal\",\"children\":\"False\"}],\"\\n\\n        \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"while\"}],\" \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"not\"}],\" done:\\n            action = agent.get_action(state, epsilon)\\n            next_state, reward, done, _, _ = env.step(action)\\n            next_state = one_hot(next_state, input_size)\\n\\n            loss = agent.train_step(state, action, reward, next_state, done)\\n            episode_reward += reward\\n            state = next_state\\n\\n        rewards_history.append(episode_reward)\\n\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" rewards_history\\n\\n\",[\"$\",\"span\",null,{\"className\":\"hljs-keyword\",\"children\":\"if\"}],\" __name__ == \",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"__main__\\\"\"}],\":\\n    rewards_history = train()\\n    success_rate = \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"sum\"}],\"(rewards_history) / \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"len\"}],\"(rewards_history) * \",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\"100\"}],\"\\n    \",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"print\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":[\"f\\\"Success rate: \",[\"$\",\"span\",null,{\"className\":\"hljs-subst\",\"children\":[\"{success_rate:\",[\"$\",\"span\",null,{\"className\":\"hljs-number\",\"children\":\".2\"}],\"f}\"]}],\"%\\\"\"]}],\")\\n\\n    plt.bar(\",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"range\"}],\"(\",[\"$\",\"span\",null,{\"className\":\"hljs-built_in\",\"children\":\"len\"}],\"(rewards_history)), rewards_history, color=\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"blue\\\"\"}],\")\\n    plt.xlabel(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"Episode\\\"\"}],\")\\n    plt.ylabel(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"Reward\\\"\"}],\")\\n    plt.title(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"Rewards per Episode\\\"\"}],\")\\n    plt.savefig(\",[\"$\",\"span\",null,{\"className\":\"hljs-string\",\"children\":\"\\\"Q-network-FrozenLake.png\\\"\"}],\")\\n\"]}],\"className\":\"overflow-x-auto bg-gray-200 rounded-lg \"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"OUTPUT\"}],\"\\n\",[\"$\",\"img\",null,{\"src\":\"./img/Q-network-FrozenLake.png\",\"alt\":\"Q-network FrozenLake\"}]]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"질문 리스트\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"원핫 인코딩의 장점?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"FrozenLake는 2차원 평면에서 이루어지는 게임이지만 해당 코드는 플레이어만 1로 표현하게 되는데, 결과가 나쁘지 않다, 이는 고정된 맵이기 때문에 특정 지역에 가면 안된다는것을 선형레이어로만으로도 학습이 되기 때문인가?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"콘볼루션 레이어는 2차원 데이터를 파악하기 쉬운 레이어라고 알고 있는데, 이때 input에 해당하는 데이터는 굳이 RGB, 흑백 이미지 데이터가 아니라 임의적으로 선언한 1부터 N까지 숫자를 매핑해줘도 될까?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"만약 된다면 1부터 N까지의 정수가 아닌 0.0부터 1.0까지의 숫자로 매핑해주는게 더 좋다는데 맞나?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"2번 과제에서 멀티프레임을 적용시켰는데, 이를 사용한 근거는 단일 프레임으론 Agent의 움직임을 파악하기 힘들거 같아서 2프레림의 데이터를 중첩시켜서 사용했다, Atari 게임 논문에서도 4Frame의 데이터를 사용했는데 이는 Agent과 환경의 움직임을 파악하기 위함이라 해석했는데 그냥 단일 프레임으로 하면 시간이 너무 오래걸려선가?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"카트폴 문제에선 환경에 대한 정보 없이 오로지 Agent의 데이터로만 학습을 진행했다(각도, 속도). 이는  외부 환경이 변하지 않기 때문이라 그런거 같은데, 환경이 변화하는 게임에서도 이러한 방식으로 학습을 진행할 수 있을까? 예를들어 꿀벌들의 위치, 말벌들의 위치, 내 위치, 내 방향 등등을 콘볼루션이 아닌 선형 레이어에 넣어서 학습을 진행한다면?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"보상을 과도하게 준다면 학습이 빠르게 진행되지만 안정성이 떨어지고, 너무 적게준다면 학습이 느리게 진행되고, 너무 복잡하게 줘도 학습이 안될수도 있고.. 최대한 심플하게 줘야 하는건가?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"보상이 너무 커서 불안정해 지는걸 막기 위해 \",[\"$\",\"code\",null,{\"children\":\"torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0) # 클리핑\",\"className\":\"overflow-x-auto bg-slate-300 px-1 rounded-md \"}],\" 이런식으로 클리핑 시켰는데 이러면 이제 안정성을 확보하면서 학습을 빠르게 징행할수 있을까?\"]}],\"\\n\"],\"className\":\"list-decimal ml-12 space-y-2 my-3\"}]]}]}]\n"])</script></body></html>