<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes"/><link rel="preload" href="/_next/static/media/885f624c3dc18cbe-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/40f13b8fccf4d106.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/10abd2b3b9bafb32.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/ea9287ddd32ae283.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/dd89e605550f760e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-d1a8f3171a66ea7d.js"/><script src="/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/_next/static/chunks/23-a9892337a8234d4f.js" async=""></script><script src="/_next/static/chunks/main-app-ce18d4723c8629f4.js" async=""></script><script src="/_next/static/chunks/578c2090-c1b891f3b6c746fd.js" async=""></script><script src="/_next/static/chunks/b563f954-758761ebc4ecc2e7.js" async=""></script><script src="/_next/static/chunks/8e1d74a4-44e18cb83de8b273.js" async=""></script><script src="/_next/static/chunks/0e762574-0fedad6633d82a8a.js" async=""></script><script src="/_next/static/chunks/231-87925b9c7247c60f.js" async=""></script><script src="/_next/static/chunks/app/%5Bsubject%5D/layout-39e3ee08b07e17b8.js" async=""></script><title>tomatom4to&#x27;s Computer Science Blog</title><meta name="description" content="Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples."/><meta name="author" content="tomatom4to"/><meta name="keywords" content="Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development"/><meta name="creator" content="tomatom4to"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://tomatom4to.github.io"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta property="og:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><meta property="og:url" content="https://tomatom4to.github.io"/><meta property="og:site_name" content="tomatom4to&#x27;s CS Blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta name="twitter:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_1e1d11 min-h-screen"><div class="grid grid-cols-[24rem_1fr] auto-rows-auto"><nav class="bg-white w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed"><a href="/">tomatoM4to&#x27;s blog</a><div class="hidden lg:flex items-center"><input type="text" class="w-36 h-7 rounded-full border-2 border-black pl-2" placeholder="search"/><div class="bg-slate-300 h-10 w-0.5 ml-2"></div><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button></div></nav><main class="col-span-2"><div class="flex"><aside class="lg:hidden"><button class=" flex flex-col gap-1 justify-center items-center w-10 h-10 rounded-lg fixed right-2 top-2 active:outline-none p-2 hover:bg-gray-200 transition-all" style="z-index:15"><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span><span class="w-6 h-0.5 bg-black rounded transition-opacity duration-300 ease-in-out opacity-100"></span><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span></button><div class="
                fixed
                top-0
                right-0
                flex
                flex-col
                px-5
                h-full
                w-7/12
                bg-white
                shadow-lg
                transform
                transition-transform
                duration-300
                ease-in-out
                translate-x-full
                " style="z-index:10"><nav class="h-14 flex items-center border-b-2"><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"></path></svg></button></nav><div class="pb-5 flex flex-col overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-RL-overview">1<!-- -->. <!-- -->RL overview</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning-overview">11<!-- -->. <!-- -->Deep learning overview</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Gradient-descent">11-1<!-- -->. <!-- -->Gradient descent</a></div></div><div class="
        w-screen
        h-screen
        bg-white
        blur-lg
        fixed
        left-0
        top-0
        transition-opacity
        duration-300
        opacity-0 pointer-events-none" style="z-index:5"></div></aside><aside class="hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-RL-overview">1<!-- -->. <!-- -->RL overview</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning-overview">11<!-- -->. <!-- -->Deep learning overview</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Gradient-descent">11-1<!-- -->. <!-- -->Gradient descent</a></aside><div class="lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden"><div class="w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body"><h1>How can we get Q*</h1>
<p>그래서 Q* 값을 얻을수 있을까? 에 대한 의문이 생깁니다. 사실 단번에 얻는거는 불가능하다 봐야하고, 알고리즘을 통해 수렴 하는 방법을 찾아야 합니다.</p>
<p>episode를 진행하면서 Q를 점점 업데이트 하며 Q<em>에 점점 다가가게 하고, 그러면 최종적으로 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span>하게 greedy 하게 하면 됩니다. 트레이닝이 끝난다면 이 Q값을 Q</em>라 믿고 사용하면 됩니다. 더이상 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span>(탐험)을 수행 안해도 됩니다. 물론 잘 안되면 다시 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span>을 수행해야 합니다.</p>
<p>이전 미로찾기 문제에서 Q-learning의 q값을 계속 업데이트 했는데 이 과정이 Q*를 찾기 위한 과정입니다.</p>
<p>이렇듯 여러번 수많은 episode를 통해 Q*를 구하는 방법에는 크게 2가지가 있습니다. 그중 첫번쨰인 Monte-Carlo 방법에 대해 알아보겠습니다.</p>
<hr class="border-t-4 border-gray-300 mt-10 mb-10"/>
<h1>Monte-Carlo Methods</h1>
<hr class="border-t-4 border-gray-300 mt-10 mb-10"/>
<h1>학습 방법</h1>
<p>다이나믹 프로그래밍 =! 강화학습이란걸 알아야함, 따로따로 발발전하다 나나중에 합친 사람이 대단한거지</p>
<p>프리딕션 == 애벌루에이션, 똑같은의미임</p>
<p>S0 -&gt; A0: 여기서파이(S0) 수행 후-&gt; R0</p>
<p>애피소드라는걸 다 알수 있단거는, 지금까지 아는대 한에선수익을 전부 알수있다</p>
<h1>First visitVS. Every visit</h1>
<p>미로찾기에서 만약내가 왔던길을 다시 가거 다시 반복하는 x1 -&gt; x2 -&gt; x1 -&gt; x2..</p>
<p>이런식으로 됄때 어느걸 선택할가에 대한 것</p>
<hr class="border-t-4 border-gray-300 mt-10 mb-10"/>
<p>몬테 카를로는 수렴할때까지 하지 않않음, 그래서 의사코드에서 while 빼고 그냥 마노이 돌돌려도됌</p>
<p>환환경이 없기 때문문에 강화학습에선 행동 가치함수만 사용하게 됀다.</p>
<p>몬테카를로에선 우리가 아는 부분에서만 가능하고, 모르는애들한테는 모모름, 환경을 아예 모르기 때문에</p>
<p>모르는 애들들한테 어떤 정책? 행행동을 수행할지지에 대해선 모험과 착취가 있겠는데</p>
<p>입실론 Greedy라고더 괜찮은 방법이 있음</p>
<p>몬테카를로에선 현재의 정책이 과거의 정책보다 더 좋다는걸 알수 이어야한다.</p>
<p>입실론 그리디를 했을때, 과거의 정책볻 현재가 더 좋다는걸 증명, 알수 있을까?</p>
<p>결국 최적의 정책으 찾을수 있는지?</p>
<p>시시그마 파이((a&#x27;|s) -e/||A|)/1-e= 1</p>
<p>온폴리시 몬테카카를로의 문제는 e/|A| 확률로만 탐험을 하게 됀다, 한마디로 자기가 아는 조그만 지식 내에서 몬갈 하는데 결국 탐험이 부족함</p>
<p>Off Policy가 강화학습에서 대부분 사용됌, 근데 좀 느리긴 함</p>
<p>예를들어 과제기간 3일남았는데 Off policy 쓰면 과제 못함, 학습시간이 3일, 2일이면 On policy 써야 함</p>
<p>DP랑 강화학습은 사실 완전히 다른 방향으로 발전했고 일부분 비슷한게 있어서 배운것 뿐이지 사실 그그냥  다른거임</p>
<hr class="border-t-4 border-gray-300 mt-10 mb-10"/>
<h1>Off-Policy Monye-Calo Methods</h1>
<p>최적의 정책을 찾는 문제의 딜레마가 있음, 최적의 행동에 대한 가치함수를 학습을 해야함, V*를 알아야 함, 근데 이걸 하려면 최적이 아닌 행동을 해야함.</p>
<p>On-Policy는 그래서 최적의 행동에 대한 가치 함수를 학습하는 대신..(ppt 내용용</p>
<p>Behavior Policy는 에피소드를 다음과 같이 생성: 배울 필요 없음, 그냥 아무거나 막 생성함 다 같은확률로</p>
<p>감마(s) 는 현재 시간에 대한 타임스탬프/ V파이(s) 가 아니라 사실 Vb(s) 다?</p>
<p>핵심: 파랑줄</p>
<hr class="border-t-4 border-gray-300 mt-10 mb-10"/>
<h2>Importance Sampling</h2>
<p>Gt: 랜덤 긷댓값, ㄱ냥 랜덤값?</p>
<h2>Estimtor</h2>
<p>사실 이러한 과저이 그렇게 간단하진 않음</p>
<p>T(t) 에피소드가 언제끝났냐에대한 예기임</p>
<p>공식상으론 맞는데 분산이 커지는걸 막아야함 -&gt; 분모를 증가시켜야함</p>
<p>[다음 ppt장]그래서 Off Policy 몬테카를를로 방식을 살거면 무지성으로 이걸 쓰면 잘 됀다.</p>
<p>왜 지금까지 V파이를 계산했나요 Q파이를 계계산하지, 더 짧으니까.. 비슷하게 생겼으니까.. V를 Q로, a 추가가하면 끝이니까</p>
<h2>Peudocode</h2>
<h2>Importance Sampling</h2>
<p>감마: 할인율을 고려 안한 문문제가 발생해서 고려해야함</p>
<p>여기서 수식중에 - 여야 하는게 +로 써져있는 오류가 있음</p>
<p>오더네리 펄 디시션 어쩌구[마지막 ppt 내용용</p>
<p>증명명돼지 않고.. 그냥 잘 돼더라</p>
<p>옾폴리시 몬테 카를를로는 아직연구가  많이 필요하다 한다.</p>
<p>실제론 MC 보단 TD를 많이 씀, 아마 과제도 TD를 할할거임</p></div></div></div></main></div><script src="/_next/static/chunks/webpack-d1a8f3171a66ea7d.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/885f624c3dc18cbe-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/40f13b8fccf4d106.css\",\"style\"]\n3:HL[\"/_next/static/css/10abd2b3b9bafb32.css\",\"style\"]\n4:HL[\"/_next/static/css/ea9287ddd32ae283.css\",\"style\"]\n5:HL[\"/_next/static/css/dd89e605550f760e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"6:I[5751,[],\"\"]\n9:I[9275,[],\"\"]\nc:I[1343,[],\"\"]\ne:I[231,[\"217\",\"static/chunks/578c2090-c1b891f3b6c746fd.js\",\"675\",\"static/chunks/b563f954-758761ebc4ecc2e7.js\",\"699\",\"static/chunks/8e1d74a4-44e18cb83de8b273.js\",\"779\",\"static/chunks/0e762574-0fedad6633d82a8a.js\",\"231\",\"static/chunks/231-87925b9c7247c60f.js\",\"874\",\"static/chunks/app/%5Bsubject%5D/layout-39e3ee08b07e17b8.js\"],\"\"]\n10:I[6130,[],\"\"]\na:[\"subject\",\"ai\",\"d\"]\nb:[\"post\",\"%5B7%5D-Monte-Carlo\",\"d\"]\n11:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/40f13b8fccf4d106.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/10abd2b3b9bafb32.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"buildId\":\"Ggd4W6vMAAu-nUgX-lKdS\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/%5B7%5D-Monte-Carlo\",\"initialTree\":[\"\",{\"children\":[[\"subject\",\"ai\",\"d\"],{\"children\":[[\"post\",\"%5B7%5D-Monte-Carlo\",\"d\"],{\"children\":[\"__PAGE__?{\\\"subject\\\":\\\"ai\\\",\\\"post\\\":\\\"[7]-Monte-Carlo\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"subject\",\"ai\",\"d\"],{\"children\":[[\"post\",\"%5B7%5D-Monte-Carlo\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L7\",\"$L8\"],null],null]},[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$a\",\"children\",\"$b\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/dd89e605550f760e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],null]},[\"$Ld\",null],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_1e1d11 min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-[24rem_1fr] auto-rows-auto\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"bg-white w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed\",\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/\",\"children\":\"tomatoM4to's blog\"}],[\"$\",\"div\",null,{\"className\":\"hidden lg:flex items-center\",\"children\":[[\"$\",\"input\",null,{\"type\":\"text\",\"className\":\"w-36 h-7 rounded-full border-2 border-black pl-2\",\"placeholder\":\"search\"}],[\"$\",\"div\",null,{\"className\":\"bg-slate-300 h-10 w-0.5 ml-2\"}],[\"$\",\"$Le\",null,{\"href\":\"https://github.com/tomatoM4to/tomatoM4to.github.io\",\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 24 24\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fill\":\"none\",\"strokeWidth\":\"2\",\"d\":\"M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278\",\"children\":[]}],[\"$\",\"path\",\"1\",{\"d\":\"M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]]}]]}],[\"$\",\"main\",null,{\"className\":\"col-span-2\",\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ea9287ddd32ae283.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}]}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$Lf\"],\"globalErrorComponent\":\"$10\",\"missingSlots\":\"$W11\"}]]\n"])</script><script>self.__next_f.push([1,"12:I[1815,[\"217\",\"static/chunks/578c2090-c1b891f3b6c746fd.js\",\"675\",\"static/chunks/b563f954-758761ebc4ecc2e7.js\",\"699\",\"static/chunks/8e1d74a4-44e18cb83de8b273.js\",\"779\",\"static/chunks/0e762574-0fedad6633d82a8a.js\",\"231\",\"static/chunks/231-87925b9c7247c60f.js\",\"874\",\"static/chunks/app/%5Bsubject%5D/layout-39e3ee08b07e17b8.js\"],\"Hamburger\"]\nf:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"10\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:title\",\"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:url\",\"content\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:site_name\",\"content\":\"tomatom4to's CS Blog\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:title\",\""])</script><script>self.__next_f.push([1,"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n7:null\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"div\",null,{\"className\":\"flex\",\"children\":[[\"$\",\"$L12\",null,{\"res\":[{\"isOutLine\":false,\"firstOrder\":1,\"secondOrder\":-1,\"order\":\"1\",\"title\":\"RL overview\",\"originalName\":\"[1]-RL-overview\"},{\"isOutLine\":false,\"firstOrder\":2,\"secondOrder\":-1,\"order\":\"2\",\"title\":\"Basis math\",\"originalName\":\"[2]-Basis-math\"},{\"isOutLine\":true,\"firstOrder\":2,\"secondOrder\":1,\"order\":\"2-1\",\"title\":\"Math with RL\",\"originalName\":\"[2-1]-Math-with-RL\"},{\"isOutLine\":false,\"firstOrder\":3,\"secondOrder\":-1,\"order\":\"3\",\"title\":\"Q learning\",\"originalName\":\"[3]-Q-learning\"},{\"isOutLine\":false,\"firstOrder\":4,\"secondOrder\":-1,\"order\":\"4\",\"title\":\"Markov process\",\"originalName\":\"[4]-Markov-process\"},{\"isOutLine\":false,\"firstOrder\":5,\"secondOrder\":-1,\"order\":\"5\",\"title\":\"Bellman Optimality Equation\",\"originalName\":\"[5]-Bellman-Optimality-Equation\"},{\"isOutLine\":false,\"firstOrder\":6,\"secondOrder\":-1,\"order\":\"6\",\"title\":\"DP\",\"originalName\":\"[6]-DP\"},{\"isOutLine\":false,\"firstOrder\":7,\"secondOrder\":-1,\"order\":\"7\",\"title\":\"Monte Carlo\",\"originalName\":\"[7]-Monte-Carlo\"},{\"isOutLine\":false,\"firstOrder\":8,\"secondOrder\":-1,\"order\":\"8\",\"title\":\"Temporal Difference Learning\",\"originalName\":\"[8]-Temporal-Difference-Learning\"},{\"isOutLine\":false,\"firstOrder\":9,\"secondOrder\":-1,\"order\":\"9\",\"title\":\"nSTEP Bootstrapping\",\"originalName\":\"[9]-nSTEP-Bootstrapping\"},{\"isOutLine\":false,\"firstOrder\":10,\"secondOrder\":-1,\"order\":\"10\",\"title\":\"Planning and Learning\",\"originalName\":\"[10]-Planning-and-Learning\"},{\"isOutLine\":true,\"firstOrder\":10,\"secondOrder\":1,\"order\":\"10-1\",\"title\":\"Function Approximation\",\"originalName\":\"[10-1]-Function-Approximation\"},{\"isOutLine\":false,\"firstOrder\":11,\"secondOrder\":-1,\"order\":\"11\",\"title\":\"Deep learning overview\",\"originalName\":\"[11]-Deep-learning-overview\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":1,\"order\":\"11-1\",\"title\":\"Gradient descent\",\"originalName\":\"[11-1]-Gradient-descent\"}],\"params\":{\"subject\":\"ai\"}}],[\"$\",\"aside\",null,{\"className\":\"hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain\",\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/ai/[1]-RL-overview\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"1\",\". \",\"RL overview\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[2]-Basis-math\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2\",\". \",\"Basis math\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[2-1]-Math-with-RL\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2-1\",\". \",\"Math with RL\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[3]-Q-learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3\",\". \",\"Q learning\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[4]-Markov-process\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"4\",\". \",\"Markov process\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[5]-Bellman-Optimality-Equation\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"5\",\". \",\"Bellman Optimality Equation\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[6]-DP\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"6\",\". \",\"DP\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[7]-Monte-Carlo\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"7\",\". \",\"Monte Carlo\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[8]-Temporal-Difference-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"8\",\". \",\"Temporal Difference Learning\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[9]-nSTEP-Bootstrapping\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"9\",\". \",\"nSTEP Bootstrapping\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[10]-Planning-and-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10\",\". \",\"Planning and Learning\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[10-1]-Function-Approximation\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10-1\",\". \",\"Function Approximation\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[11]-Deep-learning-overview\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11\",\". \",\"Deep learning overview\"]}],[\"$\",\"$Le\",null,{\"href\":\"/ai/[11-1]-Gradient-descent\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-1\",\". \",\"Gradient descent\"]}]]}],[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$a\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",null,{\"className\":\"lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"How can we get Q*\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"그래서 Q* 값을 얻을수 있을까? 에 대한 의문이 생깁니다. 사실 단번에 얻는거는 불가능하다 봐야하고, 알고리즘을 통해 수렴 하는 방법을 찾아야 합니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"episode를 진행하면서 Q를 점점 업데이트 하며 Q\",[\"$\",\"em\",null,{\"children\":[\"에 점점 다가가게 하고, 그러면 최종적으로 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"ϵ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\epsilon\"}]]}]}]}],\"하게 greedy 하게 하면 됩니다. 트레이닝이 끝난다면 이 Q값을 Q\"]}],\"라 믿고 사용하면 됩니다. 더이상 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"ϵ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\epsilon\"}]]}]}]}],\"(탐험)을 수행 안해도 됩니다. 물론 잘 안되면 다시 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"ϵ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\epsilon\"}]]}]}]}],\"을 수행해야 합니다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이전 미로찾기 문제에서 Q-learning의 q값을 계속 업데이트 했는데 이 과정이 Q*를 찾기 위한 과정입니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이렇듯 여러번 수많은 episode를 통해 Q*를 구하는 방법에는 크게 2가지가 있습니다. 그중 첫번쨰인 Monte-Carlo 방법에 대해 알아보겠습니다.\"}],\"\\n\",[\"$\",\"hr\",null,{\"className\":\"border-t-4 border-gray-300 mt-10 mb-10\",\"children\":\"$undefined\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Monte-Carlo Methods\"}],\"\\n\",[\"$\",\"hr\",null,{\"className\":\"border-t-4 border-gray-300 mt-10 mb-10\",\"children\":\"$undefined\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"학습 방법\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"다이나믹 프로그래밍 =! 강화학습이란걸 알아야함, 따로따로 발발전하다 나나중에 합친 사람이 대단한거지\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"프리딕션 == 애벌루에이션, 똑같은의미임\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"S0 -\u003e A0: 여기서파이(S0) 수행 후-\u003e R0\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"애피소드라는걸 다 알수 있단거는, 지금까지 아는대 한에선수익을 전부 알수있다\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"First visitVS. Every visit\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"미로찾기에서 만약내가 왔던길을 다시 가거 다시 반복하는 x1 -\u003e x2 -\u003e x1 -\u003e x2..\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이런식으로 됄때 어느걸 선택할가에 대한 것\"}],\"\\n\",[\"$\",\"hr\",null,{\"className\":\"border-t-4 border-gray-300 mt-10 mb-10\",\"children\":\"$undefined\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"몬테 카를로는 수렴할때까지 하지 않않음, 그래서 의사코드에서 while 빼고 그냥 마노이 돌돌려도됌\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"환환경이 없기 때문문에 강화학습에선 행동 가치함수만 사용하게 됀다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"몬테카를로에선 우리가 아는 부분에서만 가능하고, 모르는애들한테는 모모름, 환경을 아예 모르기 때문에\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"모르는 애들들한테 어떤 정책? 행행동을 수행할지지에 대해선 모험과 착취가 있겠는데\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"입실론 Greedy라고더 괜찮은 방법이 있음\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"몬테카를로에선 현재의 정책이 과거의 정책보다 더 좋다는걸 알수 이어야한다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"입실론 그리디를 했을때, 과거의 정책볻 현재가 더 좋다는걸 증명, 알수 있을까?\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"결국 최적의 정책으 찾을수 있는지?\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"시시그마 파이((a'|s) -e/||A|)/1-e= 1\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"온폴리시 몬테카카를로의 문제는 e/|A| 확률로만 탐험을 하게 됀다, 한마디로 자기가 아는 조그만 지식 내에서 몬갈 하는데 결국 탐험이 부족함\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Off Policy가 강화학습에서 대부분 사용됌, 근데 좀 느리긴 함\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"예를들어 과제기간 3일남았는데 Off policy 쓰면 과제 못함, 학습시간이 3일, 2일이면 On policy 써야 함\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"DP랑 강화학습은 사실 완전히 다른 방향으로 발전했고 일부분 비슷한게 있어서 배운것 뿐이지 사실 그그냥  다른거임\"}],\"\\n\",[\"$\",\"hr\",null,{\"className\":\"border-t-4 border-gray-300 mt-10 mb-10\",\"children\":\"$undefined\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Off-Policy Monye-Calo Methods\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"최적의 정책을 찾는 문제의 딜레마가 있음, 최적의 행동에 대한 가치함수를 학습을 해야함, V*를 알아야 함, 근데 이걸 하려면 최적이 아닌 행동을 해야함.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"On-Policy는 그래서 최적의 행동에 대한 가치 함수를 학습하는 대신..(ppt 내용용\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Behavior Policy는 에피소드를 다음과 같이 생성: 배울 필요 없음, 그냥 아무거나 막 생성함 다 같은확률로\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"감마(s) 는 현재 시간에 대한 타임스탬프/ V파이(s) 가 아니라 사실 Vb(s) 다?\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"핵심: 파랑줄\"}],\"\\n\",[\"$\",\"hr\",null,{\"className\":\"border-t-4 border-gray-300 mt-10 mb-10\",\"children\":\"$undefined\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Importance Sampling\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Gt: 랜덤 긷댓값, ㄱ냥 랜덤값?\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Estimtor\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"사실 이러한 과저이 그렇게 간단하진 않음\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"T(t) 에피소드가 언제끝났냐에대한 예기임\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"공식상으론 맞는데 분산이 커지는걸 막아야함 -\u003e 분모를 증가시켜야함\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"[다음 ppt장]그래서 Off Policy 몬테카를를로 방식을 살거면 무지성으로 이걸 쓰면 잘 됀다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"왜 지금까지 V파이를 계산했나요 Q파이를 계계산하지, 더 짧으니까.. 비슷하게 생겼으니까.. V를 Q로, a 추가가하면 끝이니까\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Peudocode\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Importance Sampling\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"감마: 할인율을 고려 안한 문문제가 발생해서 고려해야함\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"여기서 수식중에 - 여야 하는게 +로 써져있는 오류가 있음\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"오더네리 펄 디시션 어쩌구[마지막 ppt 내용용\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"증명명돼지 않고.. 그냥 잘 돼더라\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"옾폴리시 몬테 카를를로는 아직연구가  많이 필요하다 한다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"실제론 MC 보단 TD를 많이 씀, 아마 과제도 TD를 할할거임\"}]]}]}]\n"])</script></body></html>