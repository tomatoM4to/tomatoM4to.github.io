1:"$Sreact.fragment"
2:I[6874,["874","static/chunks/874-8826d48c805a2f7c.js","271","static/chunks/app/%5Btheme%5D/%5Bpost%5D/page-b8dfcb5d7be705e0.js"],""]
3:I[3853,["87","static/chunks/0e762574-2e51da01949c836e.js","874","static/chunks/874-8826d48c805a2f7c.js","177","static/chunks/app/layout-0df8caef136ee6dd.js"],"DarkModeButton"]
4:I[7555,[],""]
5:I[1295,[],""]
8:I[9665,[],"MetadataBoundary"]
a:I[9665,[],"OutletBoundary"]
d:I[4911,[],"AsyncMetadataOutlet"]
f:I[9665,[],"ViewportBoundary"]
11:I[6614,[],""]
:HL["/_next/static/media/7626ed2c039b2726-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/a34f9d1faa5f3315-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/ced12d4584c31feb.css","style"]
0:{"P":null,"b":"lKjMhT9ahl_L15O4MrwUx","p":"","c":["","ai","%5B6%5D-DP"],"i":false,"f":[[["",{"children":[["theme","ai","d"],{"children":[["post","%5B6%5D-DP","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ced12d4584c31feb.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"ko","children":["$","body",null,{"className":"__className_9b822d\n                min-h-screen\n                bg-slate-50 text-slate-900 dark:bg-slate-900 dark:text-slate-50","children":["$","div",null,{"className":"grid grid-cols-[24rem_1fr] auto-rows-auto","children":[["$","nav",null,{"className":"\n        __className_92d895\n        z-20\n        text-xl h-12 md:h-14 md:text-2xl\n        bg-slate-50/30 dark:bg-slate-900/30 border-b-slate-300 dark:border-b-slate-600\n        backdrop-blur-md\n        w-full\n        flex\n        items-center\n        justify-between\n        pl-5\n        pr-5\n        mb-20\n        border-b-2\n        border-b-slate-300\n        fixed","children":[["$","$L2",null,{"href":"/","children":"tomatoM4to's blog"}],["$","div",null,{"className":"hidden lg:flex items-center","children":[["$","input",null,{"type":"text","className":"w-36 h-7 rounded-full border-2 border-black pl-2","placeholder":"search"}],["$","div",null,{"className":"bg-slate-300 h-10 w-0.5 ml-2"}],["$","$L2",null,{"href":"https://github.com/tomatoM4to/tomatoM4to.github.io","className":"p-2 rounded-full hover:bg-slate-300 dark:hover:bg-slate-600 transition-colors duration-300","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 16 16","className":"text-2xl cursor-pointer","children":["$undefined",[["$","path","0",{"fillRule":"evenodd","clipRule":"evenodd","d":"M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z","children":[]}]]],"style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]}],["$","button",null,{"className":"p-2 rounded-full hover:bg-slate-300 dark:hover:bg-slate-600 transition-colors duration-300","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 24 24","className":"text-2xl cursor-pointer","children":["$undefined",[["$","path","0",{"fill":"none","strokeWidth":"2","d":"M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8","children":[]}]]],"style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]}],["$","$L3",null,{}]]}]]}],["$","main",null,{"className":"col-span-2","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}]}]}]]}],{"children":[["theme","ai","d"],["$","$1","c",{"children":[null,"$L6"]}],{"children":[["post","%5B6%5D-DP","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L7",["$","$L8",null,{"children":"$L9"}],null,["$","$La",null,{"children":["$Lb","$Lc",["$","$Ld",null,{"promise":"$@e"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","jiv3Qhg5_8dqR63oOpOSf",{"children":[["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],null]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:"$Sreact.suspense"
13:I[4911,[],"AsyncMetadata"]
9:["$","$12",null,{"fallback":null,"children":["$","$L13",null,{"promise":"$@14"}]}]
c:null
10:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
b:null
14:{"metadata":[["$","title","0",{"children":"Create Next App"}],["$","meta","1",{"name":"description","content":"Generated by create next app"}],["$","link","2",{"rel":"icon","href":"/icon.png?09be0199f64930e1","type":"image/png","sizes":"500x500"}]],"error":null,"digest":"$undefined"}
e:{"metadata":"$14:metadata","error":null,"digest":"$undefined"}
15:I[6903,["87","static/chunks/0e762574-2e51da01949c836e.js","206","static/chunks/5e22fd23-3096271f6014a2ab.js","949","static/chunks/578c2090-be88bc710a39c490.js","874","static/chunks/874-8826d48c805a2f7c.js","402","static/chunks/402-8a45e42f5bc1d79a.js","859","static/chunks/app/%5Btheme%5D/layout-89361a932fedae41.js"],"Hamburger"]
16:I[5830,["87","static/chunks/0e762574-2e51da01949c836e.js","206","static/chunks/5e22fd23-3096271f6014a2ab.js","949","static/chunks/578c2090-be88bc710a39c490.js","874","static/chunks/874-8826d48c805a2f7c.js","402","static/chunks/402-8a45e42f5bc1d79a.js","859","static/chunks/app/%5Btheme%5D/layout-89361a932fedae41.js"],"NonAccordionLink"]
17:I[5830,["87","static/chunks/0e762574-2e51da01949c836e.js","206","static/chunks/5e22fd23-3096271f6014a2ab.js","949","static/chunks/578c2090-be88bc710a39c490.js","874","static/chunks/874-8826d48c805a2f7c.js","402","static/chunks/402-8a45e42f5bc1d79a.js","859","static/chunks/app/%5Btheme%5D/layout-89361a932fedae41.js"],"Accordion"]
18:I[5830,["87","static/chunks/0e762574-2e51da01949c836e.js","206","static/chunks/5e22fd23-3096271f6014a2ab.js","949","static/chunks/578c2090-be88bc710a39c490.js","874","static/chunks/874-8826d48c805a2f7c.js","402","static/chunks/402-8a45e42f5bc1d79a.js","859","static/chunks/app/%5Btheme%5D/layout-89361a932fedae41.js"],"AccordionItem"]
6:["$","div",null,{"className":"flex","children":[["$","$L15",null,{"res":[{"includeHyphen":false,"firstOrder":1,"secondOrder":-1,"URL":"[1]-Introduction","title":"Introduction","contentList":[]},{"includeHyphen":false,"firstOrder":2,"secondOrder":-1,"URL":"[2]-Basis-math","title":"Basis math","contentList":[{"includeHyphen":true,"firstOrder":2,"secondOrder":1,"URL":"[2-1]-Math-with-RL","title":"Math with RL","contentList":[]}]},{"includeHyphen":false,"firstOrder":3,"secondOrder":-1,"URL":"[3]-Q-learning","title":"Q learning","contentList":[{"includeHyphen":true,"firstOrder":3,"secondOrder":1,"URL":"[3-1]-Basic-Concept","title":"Basic Concept","contentList":[]},{"includeHyphen":true,"firstOrder":3,"secondOrder":2,"URL":"[3-2]-Greedy-action","title":"Greedy action","contentList":[]},{"includeHyphen":true,"firstOrder":3,"secondOrder":3,"URL":"[3-3]-Discount-factor","title":"Discount factor","contentList":[]},{"includeHyphen":true,"firstOrder":3,"secondOrder":4,"URL":"[3-4]-Learning-rate","title":"Learning rate","contentList":[]}]},{"includeHyphen":false,"firstOrder":4,"secondOrder":-1,"URL":"[4]-Markov-process","title":"Markov process","contentList":[]},{"includeHyphen":false,"firstOrder":5,"secondOrder":-1,"URL":"[5]-Bellman-Optimality-Equation","title":"Bellman Optimality Equation","contentList":[]},{"includeHyphen":false,"firstOrder":6,"secondOrder":-1,"URL":"[6]-DP","title":"DP","contentList":[]},{"includeHyphen":false,"firstOrder":7,"secondOrder":-1,"URL":"[7]-Monte-Carlo","title":"Monte Carlo","contentList":[]},{"includeHyphen":false,"firstOrder":8,"secondOrder":-1,"URL":"[8]-Temporal-Difference-Learning","title":"Temporal Difference Learning","contentList":[]},{"includeHyphen":false,"firstOrder":9,"secondOrder":-1,"URL":"[9]-nSTEP-Bootstrapping","title":"nSTEP Bootstrapping","contentList":[]},{"includeHyphen":false,"firstOrder":10,"secondOrder":-1,"URL":"[10]-Planning-and-Learning","title":"Planning and Learning","contentList":[{"includeHyphen":true,"firstOrder":10,"secondOrder":1,"URL":"[10-1]-Function-Approximation","title":"Function Approximation","contentList":[]}]},{"includeHyphen":false,"firstOrder":11,"secondOrder":-1,"URL":"[11]-Deep-learning","title":"Deep learning","contentList":[{"includeHyphen":true,"firstOrder":11,"secondOrder":1,"URL":"[11-1]-Concept","title":"Concept","contentList":[]},{"includeHyphen":true,"firstOrder":11,"secondOrder":2,"URL":"[11-2]-Newerl-Network","title":"Newerl Network","contentList":[]},{"includeHyphen":true,"firstOrder":11,"secondOrder":3,"URL":"[11-3]-Loss-function","title":"Loss function","contentList":[]},{"includeHyphen":true,"firstOrder":11,"secondOrder":4,"URL":"[11-4]-Activation-function","title":"Activation function","contentList":[]},{"includeHyphen":true,"firstOrder":11,"secondOrder":5,"URL":"[11-5]-Gradient-descent","title":"Gradient descent","contentList":[]},{"includeHyphen":true,"firstOrder":11,"secondOrder":6,"URL":"[11-6]-Back-Propagation","title":"Back Propagation","contentList":[]}]},{"includeHyphen":false,"firstOrder":12,"secondOrder":-1,"URL":"[12]-Q-Network","title":"Q Network","contentList":[{"includeHyphen":true,"firstOrder":12,"secondOrder":1,"URL":"[12-1]-Overview","title":"Overview","contentList":[]},{"includeHyphen":true,"firstOrder":12,"secondOrder":2,"URL":"[12-2]-Frozen-Lake","title":"Frozen Lake","contentList":[]},{"includeHyphen":true,"firstOrder":12,"secondOrder":3,"URL":"[12-3]-Cartpole","title":"Cartpole","contentList":[]}]},{"includeHyphen":false,"firstOrder":13,"secondOrder":-1,"URL":"[13]-DQN","title":"DQN","contentList":[{"includeHyphen":true,"firstOrder":13,"secondOrder":1,"URL":"[13-1]-Concept","title":"Concept","contentList":[]},{"includeHyphen":true,"firstOrder":13,"secondOrder":2,"URL":"[13-2]-Cartpole","title":"Cartpole","contentList":[]}]},{"includeHyphen":false,"firstOrder":14,"secondOrder":-1,"URL":"[14]-Policy-gradient","title":"Policy gradient","contentList":[{"includeHyphen":true,"firstOrder":14,"secondOrder":1,"URL":"[14-1]-A3C","title":"A3C","contentList":[]}]}]}],["$","aside",null,{"className":"\n                hidden lg:flex w-64 2xl:w-96\n                border-r-slate-300 dark:border-r-slate-600\n                flex-col\n                h-screen\n                border-r-2\n                p-1\n                pl-5\n                pt-14\n                fixed\n                overflow-y-auto\n                overscroll-contain\n                z-auto\n                ","children":[["$","$L16","0",{"href":"./[1]-Introduction","label":"Introduction"}],["$","$L17","1",{"label":"Basis math","children":["$","$L18",null,{"contentList":"$6:props:children:0:props:res:1:contentList"}]}],["$","$L17","2",{"label":"Q learning","children":["$","$L18",null,{"contentList":"$6:props:children:0:props:res:2:contentList"}]}],["$","$L16","3",{"href":"./[4]-Markov-process","label":"Markov process"}],["$","$L16","4",{"href":"./[5]-Bellman-Optimality-Equation","label":"Bellman Optimality Equation"}],["$","$L16","5",{"href":"./[6]-DP","label":"DP"}],["$","$L16","6",{"href":"./[7]-Monte-Carlo","label":"Monte Carlo"}],["$","$L16","7",{"href":"./[8]-Temporal-Difference-Learning","label":"Temporal Difference Learning"}],["$","$L16","8",{"href":"./[9]-nSTEP-Bootstrapping","label":"nSTEP Bootstrapping"}],["$","$L17","9",{"label":"Planning and Learning","children":["$","$L18",null,{"contentList":"$6:props:children:0:props:res:9:contentList"}]}],["$","$L17","10",{"label":"Deep learning","children":["$","$L18",null,{"contentList":"$6:props:children:0:props:res:10:contentList"}]}],["$","$L17","11",{"label":"Q Network","children":["$","$L18",null,{"contentList":"$6:props:children:0:props:res:11:contentList"}]}],["$","$L17","12",{"label":"DQN","children":["$","$L18",null,{"contentList":"$6:props:children:0:props:res:12:contentList"}]}],["$","$L17","13",{"label":"Policy gradient","children":["$","$L18",null,{"contentList":"$6:props:children:0:props:res:13:contentList"}]}]]}],["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
7:["$","div",null,{"className":"lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden","children":[["$","div",null,{"className":"w-11/12 lg:w-2/3 2xl:w-1/2 markdown-body","children":[["$","h1",null,{"children":"동적계획법과 벨만 방정식","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"여기서 Q(s) = ...Q(s') 이때 s'는 다음 상태지만, s도 포함하는 상태다, s는 현재상태"}],"\n",["$","p",null,{"children":"현재의 가치상태 함수 값은 당장 받을거랑 그다음 상태로 같을때의 수익을 더한것임"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"최적 상태 가치 함수의 추정","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"DP 는 모델을 알고있고 자연스럽게 현재 상태의 최적의 행동도 알고 있다."}],"\n",["$","p",null,{"children":"근데 순차적으로 가는거라 최적의 행동을 해도 진짜 최적의 결과가 나오진 않는다."}],"\n",["$","p",null,{"children":"결국 모르는건 V*(s) or V*(s') 다."}],"\n",["$","p",null,{"children":"계속 말하지만 V*는 이론적으로 존재하는거지, 실제 조재하는지 조차 못한다."}],"\n",["$","p",null,{"children":"그래서 결국 순순차적으로 추정해야 한한다. 사실 추정하는건 불가가능하다."}],"\n",["$","h3",null,{"children":"EX)","className":" text-xl md:text-2xl font-bold my-4 text-green-600 hover:text-green-800 dark:text-green-400 dark:hover:text-green-500 transition-colors duration-200"}],"\n",["$","p",null,{"children":"전부 계산해 줬다 (교수님이)"}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"액션은 2개, 가속을 밟을지, 미친듯이 밟을지"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"그냥 엑셀을 밟을경우 노말로 들엉ㅈ만 reward 1임"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"미친듯이 밟으면 reward는 2지만 과열을 갈수도 노말로 갈수도 있음(50, 50)"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"과열된 상태에서 그냥 엘셀을 밟으면 50, 50 으로 노말을 가거나 유지함"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"과열에서 오버앨셀 하면 터짐, reward 는 10임"}],"\n"]}],"\n"],"className":"list-decimal ml-12 space-y-2 my-3"}],"\n",["$","p",null,{"children":"terminated에서 가치함수는 무조건 0이다 - 중요함"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"싱크 & 어싱크","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"그냥 어싱크 쓰셈 그게 더 좋음, 이유는 그냥 최최신걸 쓰니까.. 왜 그런진 설명 못함"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"단점: 비효율적","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"DP의 단점이기도 함"}],"\n",["$","p",null,{"children":"이전 설명에서 사실 v1 에서 최적을 찾았기 때문에 v2에 갈 필요도 없음, 더 정확해지긴 하지만"}],"\n",["$","p",null,{"children":"더이상 가치함수에 대한 변화는 없다는 거지, 근본적으로 우리가 원하는건 파이*(a) 임"}],"\n",["$","p",null,{"children":"바로 정책을 찾는거지 가지함수를 찾는게 아니기에 쓰잘데기 없는 계산을 많이함"}],"\n",["$","p",null,{"children":"이 예예에선 2개의 상태지만, 아아타리 블럭깨기만 하더라도 상태가 수억개임"}],"\n",["$","p",null,{"children":"그래서 많이 사용돼는 방식은 아니지만매우 간단함"}],"\n",["$","p",null,{"children":"두번째론 시그그마가 겹쳐져 있게 모든 상태? 를 다 계계산 해야함"}],"\n",["$","p",null,{"children":"프로그래밍 적으로 보면 2중포문을 제곱만 돌돌려야함"}],"\n",["$","p",null,{"children":"강화학습에선 속도도 매우 중요함, 게임 같은 경우는 괜찮은데 사람이랑 상호작용 하려면 비용이 매우 많이듬"}],"\n",["$","p",null,{"children":"DP는 풀면 최적 정책을 100% 보장해주지만 현실적으론 어려움"}],"\n",["$","h1",null,{"children":"Policy Evaluation","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"여기서 과거의 추정치, 새새로ㅜㄴ 추정치 같은 빨빨간색, 파란색, 보라색, 핑크색 있는 페이지에서"}],"\n",["$","p",null,{"children":["until V*(k) 여기 ",["$","em",null,{"children":"가 아니라 파이임, V"}],"(K-1) 도 *가 아니라 파이임"]}],"\n",["$","p",null,{"children":"더 낳은정책을 위해 결과값을 다시 넣고 돌리면 돼는데, 참 신기한 방식식임"}],"\n",["$","p",null,{"children":"이걸 반복하면 언젠간 수렴하고 이를 이용해 V*을 찾을수 있음"}],"\n",["$","p",null,{"children":"정책은 참 어려운 말이지만 일단 파이썬 딕셔너리라 하자"}],"\n",["$","p",null,{"children":"키로 s1, s2, s3를 넣는다"}],"\n",["$","p",null,{"children":"s1 넣으면 오른쪽 나오오고 s2 집집어 넣으면 위 나오고..."}],"\n",["$","p",null,{"children":"수렴이란건 특정 키를 넣으면 항상 오른쪽 나오는 그런거임"}],"\n",["$","p",null,{"children":"이 페이지에서 공부부한건 결국 벨만최적방정식을 찾기 위함임"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"Generalized Policy Iteration, GPI","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"댑부분의 AI는 Evaliation과 Improvment를 바뀌뀌는게 없을때까지 반복함"}],"\n",["$","p",null,{"children":"ProceduCODE는 이런작업물 없으니까 그냥 복붙 ㄱㄱ"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"Policy Iteration","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"정책은 변하지 않고 가치함수가 변한다다는것을 생각"}],"\n",["$","hr",null,{}],"\n",["$","h1",null,{"children":"동적계획법 VS 강화학습","className":" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 dark:from-blue-400 dark:via-purple-400 dark:to-pink-400"}],"\n",["$","p",null,{"children":"사실 강화학습은 나가지도 않않았음"}],"\n",["$","h2",null,{"children":"Backup Diagram","className":" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 dark:text-purple-400 dark:hover:text-purple-500 transition-colors duration-200"}],"\n",["$","p",null,{"children":"어떤 상태에서 정책에 따라 행동을 한후 보상을 받은다음 다음 상태로 감"}],"\n",["$","p",null,{"children":"DP는 모든 경우를 고고려함 이이를 full backup이라 한다."}]]}],["$","div",null,{"className":"\n            flex\n            flex-col sm:flex-row\n            justify-between\n            items-center\n            w-full\n            mt-8\n            pt-4\n            border-t-slate-300 dark:border-t-slate-600\n            border-t-2\n            w-11/12 lg:w-2/3 2xl:w-1/2\n        ","children":[["$","$L2",null,{"href":"[5]-Bellman-Optimality-Equation","className":"\n                w-full\n                flex\n                gap-2\n                justify-start\n                items-center\n                font-medium\n                py-2 sm:py-4\n                px-2\n                rounded-lg\n                hover:bg-slate-300 dark:hover:bg-slate-600\n            ","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M217.9 256L345 129c9.4-9.4 9.4-24.6 0-33.9-9.4-9.4-24.6-9.3-34 0L167 239c-9.1 9.1-9.3 23.7-.7 33.1L310.9 417c4.7 4.7 10.9 7 17 7s12.3-2.3 17-7c9.4-9.4 9.4-24.6 0-33.9L217.9 256z","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],["$","span",null,{"children":"Bellman Optimality Equation"}],false]}],["$","$L2",null,{"href":"[7]-Monte-Carlo","className":"\n                w-full\n                flex\n                gap-2\n                justify-end\n                items-center\n                font-medium\n                py-2 sm:py-4\n                px-2\n                rounded-lg\n                hover:bg-slate-300 dark:hover:bg-slate-600\n            ","children":[false,["$","span",null,{"children":"Monte Carlo"}],["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M294.1 256L167 129c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.3 34 0L345 239c9.1 9.1 9.3 23.7.7 33.1L201.1 417c-4.7 4.7-10.9 7-17 7s-12.3-2.3-17-7c-9.4-9.4-9.4-24.6 0-33.9l127-127.1z","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]]}]]}]]}]
