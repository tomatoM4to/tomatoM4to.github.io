<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes"/><link rel="preload" href="/_next/static/media/7626ed2c039b2726-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/af6a9e4b89fa7c0b.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/dd89e605550f760e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-4c38d2138fe478c3.js"/><script src="/_next/static/chunks/4bd1b696-7f4092adee896cfb.js" async=""></script><script src="/_next/static/chunks/517-eb49c20223f87188.js" async=""></script><script src="/_next/static/chunks/main-app-cdef3b2a1179051d.js" async=""></script><script src="/_next/static/chunks/578c2090-175257547869ead6.js" async=""></script><script src="/_next/static/chunks/b563f954-2e58cc71e37cba32.js" async=""></script><script src="/_next/static/chunks/8e1d74a4-98d5a7d540bb92c7.js" async=""></script><script src="/_next/static/chunks/0e762574-bccdf82862895aef.js" async=""></script><script src="/_next/static/chunks/839-ee0b8cfd2b2dd0ab.js" async=""></script><script src="/_next/static/chunks/app/%5Btheme%5D/layout-42c83d4b71ae057e.js" async=""></script><meta name="next-size-adjust"/><title>tomatom4to&#x27;s Computer Science Blog</title><meta name="description" content="Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples."/><meta name="author" content="tomatom4to"/><meta name="keywords" content="Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development"/><meta name="creator" content="tomatom4to"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://tomatom4to.github.io"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta property="og:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><meta property="og:url" content="https://tomatom4to.github.io"/><meta property="og:site_name" content="tomatom4to&#x27;s CS Blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="tomatom4to&#x27;s Computer Science Blog"/><meta name="twitter:description" content="Your gateway to comprehensive computer science knowledge and practical programming skills"/><link rel="icon" href="/icon.ico?3c4912ce8b26c1d6" type="image/x-icon" sizes="256x256"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_9b822d min-h-screen bg-slate-50 text-blue-950"><div class="grid grid-cols-[24rem_1fr] auto-rows-auto"><nav class="__className_92d895 bg-slate-50 w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed"><a href="/">tomatoM4to&#x27;s blog</a><div class="hidden lg:flex items-center"><input type="text" class="w-36 h-7 rounded-full border-2 border-black pl-2" placeholder="search"/><div class="bg-slate-300 h-10 w-0.5 ml-2"></div><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button></div></nav><main class="col-span-2"><div class="flex"><aside class="lg:hidden"><button class=" flex flex-col gap-1 justify-center items-center w-10 h-10 rounded-lg fixed right-2 top-2 active:outline-none p-2 hover:bg-gray-200 transition-all" style="z-index:15"><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span><span class="w-6 h-0.5 bg-black rounded transition-opacity duration-300 ease-in-out opacity-100"></span><span class="w-6 h-0.5 bg-black rounded transform transition-transform duration-300 ease-in-out "></span></button><div class="
                bg-slate-50
                fixed
                top-0
                right-0
                flex
                flex-col
                px-5
                h-full
                w-7/12
                shadow-lg
                transform
                transition-transform
                duration-300
                ease-in-out
                translate-x-full
                " style="z-index:10"><nav class="h-14 flex items-center border-b-2"><a class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300" href="https://github.com/tomatoM4to/tomatoM4to.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-2xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z"></path></svg></a><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-width="2" d="M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></button><button class="p-2 rounded-full hover:bg-gray-300 transition-colors duration-300"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="text-xl cursor-pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"></path></svg></button></nav><div class="pb-5 flex flex-col overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-Introduction">1<!-- -->. <!-- -->Introduction</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-1]-Basic-Concept">3-1<!-- -->. <!-- -->Basic Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-2]-Greedy-action">3-2<!-- -->. <!-- -->Greedy action</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-3]-Discount-factor">3-3<!-- -->. <!-- -->Discount factor</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-4]-Learning-rate">3-4<!-- -->. <!-- -->Learning rate</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning">11<!-- -->. <!-- -->Deep learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Concept">11-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-2]-Newerl-Network">11-2<!-- -->. <!-- -->Newerl Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-3]-Loss-function">11-3<!-- -->. <!-- -->Loss function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-4]-Activation-function">11-4<!-- -->. <!-- -->Activation function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-5]-Gradient-descent">11-5<!-- -->. <!-- -->Gradient descent</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-6]-Back-Propagation">11-6<!-- -->. <!-- -->Back Propagation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12]-Q-Network">12<!-- -->. <!-- -->Q Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-1]-Frozen-Lake">12-1<!-- -->. <!-- -->Frozen Lake</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-2]-Cartpole">12-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13]-DQN">13<!-- -->. <!-- -->DQN</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-1]-Concept">13-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-2]-Cartpole">13-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[14]-Policy-gradient">14<!-- -->. <!-- -->Policy gradient</a></div></div><div class="
        w-screen
        h-screen
        bg-white
        blur-lg
        fixed
        left-0
        top-0
        transition-opacity
        duration-300
        opacity-0 pointer-events-none" style="z-index:5"></div></aside><aside class="hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain"><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[1]-Introduction">1<!-- -->. <!-- -->Introduction</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2]-Basis-math">2<!-- -->. <!-- -->Basis math</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[2-1]-Math-with-RL">2-1<!-- -->. <!-- -->Math with RL</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3]-Q-learning">3<!-- -->. <!-- -->Q learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-1]-Basic-Concept">3-1<!-- -->. <!-- -->Basic Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-2]-Greedy-action">3-2<!-- -->. <!-- -->Greedy action</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-3]-Discount-factor">3-3<!-- -->. <!-- -->Discount factor</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[3-4]-Learning-rate">3-4<!-- -->. <!-- -->Learning rate</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[4]-Markov-process">4<!-- -->. <!-- -->Markov process</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[5]-Bellman-Optimality-Equation">5<!-- -->. <!-- -->Bellman Optimality Equation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[6]-DP">6<!-- -->. <!-- -->DP</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[7]-Monte-Carlo">7<!-- -->. <!-- -->Monte Carlo</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[8]-Temporal-Difference-Learning">8<!-- -->. <!-- -->Temporal Difference Learning</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[9]-nSTEP-Bootstrapping">9<!-- -->. <!-- -->nSTEP Bootstrapping</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10]-Planning-and-Learning">10<!-- -->. <!-- -->Planning and Learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[10-1]-Function-Approximation">10-1<!-- -->. <!-- -->Function Approximation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11]-Deep-learning">11<!-- -->. <!-- -->Deep learning</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-1]-Concept">11-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-2]-Newerl-Network">11-2<!-- -->. <!-- -->Newerl Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-3]-Loss-function">11-3<!-- -->. <!-- -->Loss function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-4]-Activation-function">11-4<!-- -->. <!-- -->Activation function</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-5]-Gradient-descent">11-5<!-- -->. <!-- -->Gradient descent</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[11-6]-Back-Propagation">11-6<!-- -->. <!-- -->Back Propagation</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12]-Q-Network">12<!-- -->. <!-- -->Q Network</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-1]-Frozen-Lake">12-1<!-- -->. <!-- -->Frozen Lake</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[12-2]-Cartpole">12-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13]-DQN">13<!-- -->. <!-- -->DQN</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-1]-Concept">13-1<!-- -->. <!-- -->Concept</a><a class="pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[13-2]-Cartpole">13-2<!-- -->. <!-- -->Cartpole</a><a class="undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg" href="/ai/[14]-Policy-gradient">14<!-- -->. <!-- -->Policy gradient</a></aside><div class="lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden"><div class="w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body"><h1 class=" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">문제 발생</h1>
<p>이번 시간에는 강화학습에서 가장 중요한 알고리즘이라 할수 있는 DQN에 대해 알아보겠습니다.</p>
<p>지난 시간에 Q-table로 Q-learning를 구현하고, 이 Q-table의 한계 때문에 Network를 이용하여 Q-learning을 구현하는 방법을 알아보았습니다. 하지만 코드를 실행하면 알수 있듯 그 결과가 매우 형편없었습니다 단순한 미로나 막대기를 새우는 문제조차 제대로 풀지 못했습니다. 이번엔 왜 이런 문제가 발생했는지 또 해결 방법은 무엇인지 알아보겠습니다.</p>
<p>이전에 말했듯 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{Q}</annotation></semantics></math></span> 은 Converges 하지 않는단 이유를 가지고 있었습니다.</p>
<ul class="list-disc ml-12 space-y-2 my-3">
<li>Correlations between samples(샘플간의 상관관계)</li>
<li>Non-stationary targets(움직이는 타겟)</li>
</ul>
<p>이러한 이유 때문에 신명망을 사용하면 차이가 발생합니다. 이는 학습이 잘 돼지 않는다는 의미입니다.</p>
<p>사실 Q-learning과 NN을 결합시키려는 시도는 매우 오래전부터 있었습니다. 하지만 저 2가지 문제를 해결해 이를 성공적으로 구현한 것은 2013년 DeepMind의 연구팀이었습니다. 이들은 Q-learning을 이용하여 Atari 게임을 플레이하는 AI를 만들었는데, 이것이 바로 DQN입니다.</p>
<ul class="list-disc ml-12 space-y-2 my-3">
<li>DQN paper: <a href="https://nature.com/articles/nature14236">https://nature.com/articles/nature14236</a>
한번쯤 읽어보시길 추천드립니다.</li>
</ul>
<hr/>
<h1 class=" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">문제점</h1>
<p>기존의 문제가 뭘까요?</p>
<ul class="list-disc ml-12 space-y-2 my-3">
<li>Correlations between samples(샘플간의 상관관계)</li>
<li>Non-stationary targets(움직이는 타겟)</li>
</ul>
<p>이겁니다. 이를 해결하기 위해 DeepMind 팀은 간단한 솔류션을 제시했습니다.</p>
<p>한번 생각해 봅시다. 미로를 탈출한다고 했을때, 혹은 이전처럼 막대기를 새운다 했을때 0.1초전과 지금의 상태는 많이 다를까요? 음 그렇진 않거 같습니다. 상당히 유사한 상태일 것입니다. action을 취할시 환경이 급격히 바뀌는게 아닌 조금씩 바뀌기 때문에, 받아오는 데이터들 혹은 sample 들의 연관성이 유사하단 점이 바로 문젭니다.</p>
<p>TODO: Linear regression 그래프 예제 필요</p>
<p>두번째는 타켓이 움직인다 라는 겁니다.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mi>T</mi></munderover><mo stretchy="false">[</mo><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mo stretchy="false">]</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\min_{\theta} \sum_{t=0}^T [\hat{Q}(s_t, a_t|\theta) - (r_t + \gamma \max_{a&#x27;}\hat{Q}(s_{t+1}, a&#x27;|\theta))]^2
</annotation></semantics></math></span>
<p>이전 공식에서 주의해서 보아야 할것이 두부분 있습니다.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{Q}(s_t, a_t|\theta)
</annotation></semantics></math></span>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(r_t + \gamma \max_{a&#x27;}\hat{Q}(s_{t+1}, a&#x27;|\theta))
</annotation></semantics></math></span>
<p>이 두 Q값이 서로 같은 신경망을 통해 계산되기 때문에, 이 두 Q값이 서로 영향을 주게 됩니다. 이는 Non-stationary targets 라는 문제를 발생시킵니다.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{Q}(s_t, a_t|\theta)</annotation></semantics></math></span> 부분에서 다음 상태에 가까워 지기 위해 네트워크를 업데이트 시키고 그 다음 계산인 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(r_t + \gamma \max_{a&#x27;}\hat{Q}(s_{t+1}, a&#x27;|\theta))</annotation></semantics></math></span> 부분에서는 업데이트된 네트워크를 사용하고 다시 업데이트를 시킵니다. 확실히 문제가 발생할 수 밖에 없습니다.</p>
<hr/>
<h1 class=" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">DQN&#x27;s three solutions</h1>
<p>이 문제를 해결하기 위해 DeepMind 팀은 3가지 솔루션을 제시했습니다.</p>
<ol class="list-decimal ml-12 space-y-2 my-3">
<li>Go deep: 더 깊은 신경망을 사용한다.</li>
<li>Capture and replay: Correlations between samples(샘플간의 상관관계)를 해결하기 위해 sample을 저장하고 랜덤하게 뽑아서 학습한다.</li>
<li>Separate networks: Non-stationary targets(움직이는 타겟)를 해결하기 위해 2개의 네트워크를 사용한다.</li>
</ol>
<h2 class=" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200">Go deep</h2>
<p>시원시원한 생각이죠, 이전엔 하나의 layer만 사용한걸 늘리면 되겠다는 생각입니다. 이는 더 복잡한 문제를 풀 수 있게 해줍니다.</p>
<ul class="list-disc ml-12 space-y-2 my-3">
<li>End-to-end learning of values Q(S, a) from pixels s</li>
<li>Input state s is stack of raw pixels from last 4 frames</li>
<li>Output is Q(s, a) for 18 joystick/button positions</li>
<li>Reward is change in score for that frame</li>
</ul>
<p>TODO: 위 내용 이해 필요, 설명 없었음</p>
<h2 class=" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200">Capture and replay</h2>
<p>굉장히 중유한 솔루션 입니다. 너무 연관있는 데이터들로 학습을 시키니 학습이 잘 돼지 않았던 문제를 해결하기 위해 experience replay라는 방법을 사용합니다.</p>
<p>Agent 에게 action을 취하게 하는 루프를 돌면 이 action을 통해 상태를 받아오게 돼는데 이전엔 바로바로 학습을 시켰습니다. 이를 바꿔숴 중간에 버퍼에 저장을 한다음, 이 버퍼가 다 차면 혹은 일정한 시간이 지나면 해당 버퍼의 담겨진 데이터중 랜덤으로 하나 뽑아서 학습을 시킵니다.\</p>
<p>TODO: 사진</p>
<p>TODO: 의사 코드 사진 필요</p>
<ul class="list-disc ml-12 space-y-2 my-3">
<li><strong>Store transitions (s, a, r, s&#x27;) in replay memory D</strong>: action을 취한다음 D 라는 버퍼에다가 상태, 액션, 보상, 다음 상태를 저장합니다.</li>
<li><strong>Sample random minibatch of transitions (s, a, r, s&#x27;) from D</strong>: D에서 랜덤하게 샘플을 뽑아 mini batch를 만들어 이걸 가지고 학습을 진행합니다.</li>
</ul>
<p>아주 간단한 아이디어지만 왜 될까요?</p>
<p>눈치 채신분들도 많겠지만 이렇게 해봅시다.</p>
<p>버퍼에 어느정도 데이터가 쌓어셔 이걸 그래프로 표현해보겠습니다.</p>
<p>이런 그래프가 나왔을때 기존엔 편향된 데이터가 학습이 될수 있었지만 이들중 몇개만 랜덤으로 뽑아 학습을 하게 되면 우리가 원했던 기울기의 그래프가 나올 가능성이 훨씬 크지 않을까요? 아주 심플한 아이디어지만 실제로 매우 잘 작동합니다.</p>
<h2 class=" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200">Separate networks</h2>
<p>이또한 매우 심플한 아이디어죠, 사용하는 NN가 같아 Non-stationary targets 문제가 발생했는데, 이를 해결하기 위해 2개의 네트워크를 사용합니다.</p>
<p>공식에 익숙해 졌을거라 생각하니 바로 공식부터 보여드리면 이렇습니다.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mi>T</mi></munderover><mo stretchy="false">[</mo><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mover accent="true"><mi>θ</mi><mo>ˉ</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mo stretchy="false">]</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\min_{\theta} \sum_{t=0}^T [\hat{Q}(s_t, a_t|\theta) - (r_t + \gamma \max_{a&#x27;}\hat{Q}(s_{t+1}, a&#x27;|\bar{\theta}))]^2
</annotation></semantics></math></span>
<p>양쪽 Q의 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span> 가 다르다는것을 바로 눈치채실수 있을겁니다. 이는 서로 다른 NN을 사용한다는 의밉니다.</p>
<p>이때 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{Q}(s_t, a_t|\theta)</annotation></semantics></math></span> 에서 사용돼는 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span> 를 policy network라고 부르고, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mover accent="true"><mi>θ</mi><mo>ˉ</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(r_t + \gamma \max_{a&#x27;}\hat{Q}(s_{t+1}, a&#x27;|\bar{\theta}))</annotation></semantics></math></span> 에서 사용되는 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>ˉ</mo></mover></mrow><annotation encoding="application/x-tex">\bar{\theta}</annotation></semantics></math></span> 를 target network라고 부릅니다.</p>
<p>중요한점은 학습을 시킬때는 policy network 많을 업데이트 시킵니다. target network는 움직이지 않고 있다가 policy network가 일정한 시간이 지나거나 일정한 횟수만큼 업데이트 될때마다 policy network의 weight를 target network로 복사합니다.</p>
<p>TODO: 의사코드</p>
<p>정말 심플하지만 이또한 정말 잘 작동합니다.</p>
<hr/>
<h1 class=" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500">요약</h1>
<p>TODO: 의사코드와 요약</p></div></div></div></main></div><script src="/_next/static/chunks/webpack-4c38d2138fe478c3.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"5:\"$Sreact.fragment\"\n6:I[4839,[\"949\",\"static/chunks/578c2090-175257547869ead6.js\",\"585\",\"static/chunks/b563f954-2e58cc71e37cba32.js\",\"711\",\"static/chunks/8e1d74a4-98d5a7d540bb92c7.js\",\"87\",\"static/chunks/0e762574-bccdf82862895aef.js\",\"839\",\"static/chunks/839-ee0b8cfd2b2dd0ab.js\",\"859\",\"static/chunks/app/%5Btheme%5D/layout-42c83d4b71ae057e.js\"],\"\"]\n7:I[5244,[],\"\"]\n8:I[3866,[],\"\"]\nb:I[6213,[],\"OutletBoundary\"]\nd:I[6213,[],\"MetadataBoundary\"]\nf:I[6213,[],\"ViewportBoundary\"]\n11:I[4835,[],\"\"]\n1:HL[\"/_next/static/media/7626ed2c039b2726-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/css/af6a9e4b89fa7c0b.css\",\"style\"]\n4:HL[\"/_next/static/css/dd89e605550f760e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"GLc5m3w7TedaZMM4mRKfi\",\"p\":\"\",\"c\":[\"\",\"ai\",\"%5B13-1%5D-Concept\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"theme\",\"ai\",\"d\"],{\"children\":[[\"post\",\"%5B13-1%5D-Concept\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$5\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/af6a9e4b89fa7c0b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_9b822d min-h-screen bg-slate-50 text-blue-950\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-[24rem_1fr] auto-rows-auto\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"__className_92d895 bg-slate-50 w-full h-14 flex items-center justify-between pl-5 pr-5 mb-20 border-b-2 border-b-slate-300 text-2xl fixed\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"/\",\"children\":\"tomatoM4to's blog\"}],[\"$\",\"div\",null,{\"className\":\"hidden lg:flex items-center\",\"children\":[[\"$\",\"input\",null,{\"type\":\"text\",\"className\":\"w-36 h-7 rounded-full border-2 border-black pl-2\",\"placeholder\":\"search\"}],[\"$\",\"div\",null,{\"className\":\"bg-slate-300 h-10 w-0.5 ml-2\"}],[\"$\",\"$L6\",null,{\"href\":\"https://github.com/tomatoM4to/tomatoM4to.github.io\",\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M7.976 0A7.977 7.977 0 0 0 0 7.976c0 3.522 2.3 6.507 5.431 7.584.392.049.538-.196.538-.392v-1.37c-2.201.49-2.69-1.076-2.69-1.076-.343-.93-.881-1.175-.881-1.175-.734-.489.048-.489.048-.489.783.049 1.224.832 1.224.832.734 1.223 1.859.88 2.3.685.048-.538.293-.88.489-1.076-1.762-.196-3.621-.881-3.621-3.964 0-.88.293-1.566.832-2.153-.05-.147-.343-.978.098-2.055 0 0 .685-.196 2.201.832.636-.196 1.322-.245 2.007-.245s1.37.098 2.006.245c1.517-1.027 2.202-.832 2.202-.832.44 1.077.146 1.908.097 2.104a3.16 3.16 0 0 1 .832 2.153c0 3.083-1.86 3.719-3.62 3.915.293.244.538.733.538 1.467v2.202c0 .196.146.44.538.392A7.984 7.984 0 0 0 16 7.976C15.951 3.572 12.38 0 7.976 0z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 24 24\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fill\":\"none\",\"strokeWidth\":\"2\",\"d\":\"M12,23 C18.0751322,23 23,18.0751322 23,12 C23,5.92486775 18.0751322,1 12,1 C5.92486775,1 1,5.92486775 1,12 C1,18.0751322 5.92486775,23 12,23 Z M12,23 C15,23 16,18 16,12 C16,6 15,1 12,1 C9,1 8,6 8,12 C8,18 9,23 12,23 Z M2,16 L22,16 M2,8 L22,8\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"button\",null,{\"className\":\"p-2 rounded-full hover:bg-gray-300 transition-colors duration-300\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 16 16\",\"className\":\"text-2xl cursor-pointer\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278\",\"children\":[]}],[\"$\",\"path\",\"1\",{\"d\":\"M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]]}]]}],[\"$\",\"main\",null,{\"className\":\"col-span-2\",\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}]]}]}]}]]}],{\"children\":[[\"theme\",\"ai\",\"d\"],[\"$\",\"$5\",\"c\",{\"children\":[null,\"$L9\"]}],{\"children\":[[\"post\",\"%5B13-1%5D-Concept\",\"d\"],[\"$\",\"$5\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$0:f:0:1:2:children:0\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$5\",\"c\",{\"children\":[\"$La\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/dd89e605550f760e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null]},null]},null]},null],[\"$\",\"$5\",\"h\",{\"children\":[null,[\"$\",\"$5\",\"6XNRFmgewq34h_kKvpKNH\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\"}]]}]]}]]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=yes\"}]]\ne:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Comprehensive computer science knowledge covering OS, Database, AI, Networks, Linux, and Docker. Learn computer science concepts with clear explanations and practical examples.\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"Computer Science,Operating Systems,Database,AI,Network,Linux,Docker,Programming,Software Development\"}],[\"$\",\"meta\",\"5\",{\"name\":\"creator\",\"content\":\"tomatom4to\"}],[\"$\",\"meta\",\"6\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"7\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"8\",{\"rel\":\"canonical\",\"href\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"9\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://tomatom4to.github.io\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"tomatom4to's CS Blog\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:title\",\"content\":\"tomatom4to's Computer Science Blog\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:description\",\"content\":\"Your gateway to comprehensive computer science knowledge and practical programming skills\"}],[\"$\",\"link\",\"19\",{\"rel\":\"icon\",\"href\":\"/icon.ico?3c4912ce8b26c1d6\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}]]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script><script>self.__next_f.push([1,"12:I[5739,[\"949\",\"static/chunks/578c2090-175257547869ead6.js\",\"585\",\"static/chunks/b563f954-2e58cc71e37cba32.js\",\"711\",\"static/chunks/8e1d74a4-98d5a7d540bb92c7.js\",\"87\",\"static/chunks/0e762574-bccdf82862895aef.js\",\"839\",\"static/chunks/839-ee0b8cfd2b2dd0ab.js\",\"859\",\"static/chunks/app/%5Btheme%5D/layout-42c83d4b71ae057e.js\"],\"Hamburger\"]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"div\",null,{\"className\":\"flex\",\"children\":[[\"$\",\"$L12\",null,{\"res\":[{\"isOutLine\":false,\"firstOrder\":1,\"secondOrder\":-1,\"order\":\"1\",\"title\":\"Introduction\",\"originalName\":\"[1]-Introduction\"},{\"isOutLine\":false,\"firstOrder\":2,\"secondOrder\":-1,\"order\":\"2\",\"title\":\"Basis math\",\"originalName\":\"[2]-Basis-math\"},{\"isOutLine\":true,\"firstOrder\":2,\"secondOrder\":1,\"order\":\"2-1\",\"title\":\"Math with RL\",\"originalName\":\"[2-1]-Math-with-RL\"},{\"isOutLine\":false,\"firstOrder\":3,\"secondOrder\":-1,\"order\":\"3\",\"title\":\"Q learning\",\"originalName\":\"[3]-Q-learning\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":1,\"order\":\"3-1\",\"title\":\"Basic Concept\",\"originalName\":\"[3-1]-Basic-Concept\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":2,\"order\":\"3-2\",\"title\":\"Greedy action\",\"originalName\":\"[3-2]-Greedy-action\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":3,\"order\":\"3-3\",\"title\":\"Discount factor\",\"originalName\":\"[3-3]-Discount-factor\"},{\"isOutLine\":true,\"firstOrder\":3,\"secondOrder\":4,\"order\":\"3-4\",\"title\":\"Learning rate\",\"originalName\":\"[3-4]-Learning-rate\"},{\"isOutLine\":false,\"firstOrder\":4,\"secondOrder\":-1,\"order\":\"4\",\"title\":\"Markov process\",\"originalName\":\"[4]-Markov-process\"},{\"isOutLine\":false,\"firstOrder\":5,\"secondOrder\":-1,\"order\":\"5\",\"title\":\"Bellman Optimality Equation\",\"originalName\":\"[5]-Bellman-Optimality-Equation\"},{\"isOutLine\":false,\"firstOrder\":6,\"secondOrder\":-1,\"order\":\"6\",\"title\":\"DP\",\"originalName\":\"[6]-DP\"},{\"isOutLine\":false,\"firstOrder\":7,\"secondOrder\":-1,\"order\":\"7\",\"title\":\"Monte Carlo\",\"originalName\":\"[7]-Monte-Carlo\"},{\"isOutLine\":false,\"firstOrder\":8,\"secondOrder\":-1,\"order\":\"8\",\"title\":\"Temporal Difference Learning\",\"originalName\":\"[8]-Temporal-Difference-Learning\"},{\"isOutLine\":false,\"firstOrder\":9,\"secondOrder\":-1,\"order\":\"9\",\"title\":\"nSTEP Bootstrapping\",\"originalName\":\"[9]-nSTEP-Bootstrapping\"},{\"isOutLine\":false,\"firstOrder\":10,\"secondOrder\":-1,\"order\":\"10\",\"title\":\"Planning and Learning\",\"originalName\":\"[10]-Planning-and-Learning\"},{\"isOutLine\":true,\"firstOrder\":10,\"secondOrder\":1,\"order\":\"10-1\",\"title\":\"Function Approximation\",\"originalName\":\"[10-1]-Function-Approximation\"},{\"isOutLine\":false,\"firstOrder\":11,\"secondOrder\":-1,\"order\":\"11\",\"title\":\"Deep learning\",\"originalName\":\"[11]-Deep-learning\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":1,\"order\":\"11-1\",\"title\":\"Concept\",\"originalName\":\"[11-1]-Concept\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":2,\"order\":\"11-2\",\"title\":\"Newerl Network\",\"originalName\":\"[11-2]-Newerl-Network\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":3,\"order\":\"11-3\",\"title\":\"Loss function\",\"originalName\":\"[11-3]-Loss-function\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":4,\"order\":\"11-4\",\"title\":\"Activation function\",\"originalName\":\"[11-4]-Activation-function\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":5,\"order\":\"11-5\",\"title\":\"Gradient descent\",\"originalName\":\"[11-5]-Gradient-descent\"},{\"isOutLine\":true,\"firstOrder\":11,\"secondOrder\":6,\"order\":\"11-6\",\"title\":\"Back Propagation\",\"originalName\":\"[11-6]-Back-Propagation\"},{\"isOutLine\":false,\"firstOrder\":12,\"secondOrder\":-1,\"order\":\"12\",\"title\":\"Q Network\",\"originalName\":\"[12]-Q-Network\"},{\"isOutLine\":true,\"firstOrder\":12,\"secondOrder\":1,\"order\":\"12-1\",\"title\":\"Frozen Lake\",\"originalName\":\"[12-1]-Frozen-Lake\"},{\"isOutLine\":true,\"firstOrder\":12,\"secondOrder\":2,\"order\":\"12-2\",\"title\":\"Cartpole\",\"originalName\":\"[12-2]-Cartpole\"},{\"isOutLine\":false,\"firstOrder\":13,\"secondOrder\":-1,\"order\":\"13\",\"title\":\"DQN\",\"originalName\":\"[13]-DQN\"},{\"isOutLine\":true,\"firstOrder\":13,\"secondOrder\":1,\"order\":\"13-1\",\"title\":\"Concept\",\"originalName\":\"[13-1]-Concept\"},{\"isOutLine\":true,\"firstOrder\":13,\"secondOrder\":2,\"order\":\"13-2\",\"title\":\"Cartpole\",\"originalName\":\"[13-2]-Cartpole\"},{\"isOutLine\":false,\"firstOrder\":14,\"secondOrder\":-1,\"order\":\"14\",\"title\":\"Policy gradient\",\"originalName\":\"[14]-Policy-gradient\"}],\"params\":{\"theme\":\"ai\"}}],[\"$\",\"aside\",null,{\"className\":\"hidden lg:flex w-64 2xl:w-96 flex-col h-screen border-r-2 border-gray-300 mt-14 p-1 pl-5 fixed overflow-y-auto overscroll-contain\",\"children\":[[\"$\",\"$L6\",\"1\",{\"href\":\"/ai/[1]-Introduction\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"1\",\". \",\"Introduction\"]}],[\"$\",\"$L6\",\"2\",{\"href\":\"/ai/[2]-Basis-math\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2\",\". \",\"Basis math\"]}],[\"$\",\"$L6\",\"2-1\",{\"href\":\"/ai/[2-1]-Math-with-RL\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"2-1\",\". \",\"Math with RL\"]}],[\"$\",\"$L6\",\"3\",{\"href\":\"/ai/[3]-Q-learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3\",\". \",\"Q learning\"]}],[\"$\",\"$L6\",\"3-1\",{\"href\":\"/ai/[3-1]-Basic-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-1\",\". \",\"Basic Concept\"]}],[\"$\",\"$L6\",\"3-2\",{\"href\":\"/ai/[3-2]-Greedy-action\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-2\",\". \",\"Greedy action\"]}],[\"$\",\"$L6\",\"3-3\",{\"href\":\"/ai/[3-3]-Discount-factor\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-3\",\". \",\"Discount factor\"]}],[\"$\",\"$L6\",\"3-4\",{\"href\":\"/ai/[3-4]-Learning-rate\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"3-4\",\". \",\"Learning rate\"]}],[\"$\",\"$L6\",\"4\",{\"href\":\"/ai/[4]-Markov-process\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"4\",\". \",\"Markov process\"]}],[\"$\",\"$L6\",\"5\",{\"href\":\"/ai/[5]-Bellman-Optimality-Equation\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"5\",\". \",\"Bellman Optimality Equation\"]}],[\"$\",\"$L6\",\"6\",{\"href\":\"/ai/[6]-DP\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"6\",\". \",\"DP\"]}],[\"$\",\"$L6\",\"7\",{\"href\":\"/ai/[7]-Monte-Carlo\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"7\",\". \",\"Monte Carlo\"]}],[\"$\",\"$L6\",\"8\",{\"href\":\"/ai/[8]-Temporal-Difference-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"8\",\". \",\"Temporal Difference Learning\"]}],[\"$\",\"$L6\",\"9\",{\"href\":\"/ai/[9]-nSTEP-Bootstrapping\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"9\",\". \",\"nSTEP Bootstrapping\"]}],[\"$\",\"$L6\",\"10\",{\"href\":\"/ai/[10]-Planning-and-Learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10\",\". \",\"Planning and Learning\"]}],[\"$\",\"$L6\",\"10-1\",{\"href\":\"/ai/[10-1]-Function-Approximation\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"10-1\",\". \",\"Function Approximation\"]}],[\"$\",\"$L6\",\"11\",{\"href\":\"/ai/[11]-Deep-learning\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11\",\". \",\"Deep learning\"]}],[\"$\",\"$L6\",\"11-1\",{\"href\":\"/ai/[11-1]-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-1\",\". \",\"Concept\"]}],[\"$\",\"$L6\",\"11-2\",{\"href\":\"/ai/[11-2]-Newerl-Network\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-2\",\". \",\"Newerl Network\"]}],[\"$\",\"$L6\",\"11-3\",{\"href\":\"/ai/[11-3]-Loss-function\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-3\",\". \",\"Loss function\"]}],[\"$\",\"$L6\",\"11-4\",{\"href\":\"/ai/[11-4]-Activation-function\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-4\",\". \",\"Activation function\"]}],[\"$\",\"$L6\",\"11-5\",{\"href\":\"/ai/[11-5]-Gradient-descent\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-5\",\". \",\"Gradient descent\"]}],[\"$\",\"$L6\",\"11-6\",{\"href\":\"/ai/[11-6]-Back-Propagation\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"11-6\",\". \",\"Back Propagation\"]}],[\"$\",\"$L6\",\"12\",{\"href\":\"/ai/[12]-Q-Network\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12\",\". \",\"Q Network\"]}],[\"$\",\"$L6\",\"12-1\",{\"href\":\"/ai/[12-1]-Frozen-Lake\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12-1\",\". \",\"Frozen Lake\"]}],[\"$\",\"$L6\",\"12-2\",{\"href\":\"/ai/[12-2]-Cartpole\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"12-2\",\". \",\"Cartpole\"]}],[\"$\",\"$L6\",\"13\",{\"href\":\"/ai/[13]-DQN\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13\",\". \",\"DQN\"]}],[\"$\",\"$L6\",\"13-1\",{\"href\":\"/ai/[13-1]-Concept\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13-1\",\". \",\"Concept\"]}],[\"$\",\"$L6\",\"13-2\",{\"href\":\"/ai/[13-2]-Cartpole\",\"className\":\"pl-4 px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"13-2\",\". \",\"Cartpole\"]}],[\"$\",\"$L6\",\"14\",{\"href\":\"/ai/[14]-Policy-gradient\",\"className\":\"undefined px-2 py-1 mb-1 hover:bg-gray-300 transition-colors rounded-lg\",\"onClick\":\"$undefined\",\"children\":[\"14\",\". \",\"Policy gradient\"]}]]}],[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$0:f:0:1:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"div\",null,{\"className\":\"lg:ml-64 2xl:ml-96 mt-32 mb-32 flex-1 flex flex-col items-center overflow-x-hidden\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-11/12 md:w-3/4 lg:w-2/3 2xl:w-1/2 markdown-body\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"문제 발생\",\"className\":\" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이번 시간에는 강화학습에서 가장 중요한 알고리즘이라 할수 있는 DQN에 대해 알아보겠습니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"지난 시간에 Q-table로 Q-learning를 구현하고, 이 Q-table의 한계 때문에 Network를 이용하여 Q-learning을 구현하는 방법을 알아보았습니다. 하지만 코드를 실행하면 알수 있듯 그 결과가 매우 형편없었습니다 단순한 미로나 막대기를 새우는 문제조차 제대로 풀지 못했습니다. 이번엔 왜 이런 문제가 발생했는지 또 해결 방법은 무엇인지 알아보겠습니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"이전에 말했듯 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\hat{Q}\"}]]}]}]}],\" 은 Converges 하지 않는단 이유를 가지고 있었습니다.\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Correlations between samples(샘플간의 상관관계)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Non-stationary targets(움직이는 타겟)\"}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이러한 이유 때문에 신명망을 사용하면 차이가 발생합니다. 이는 학습이 잘 돼지 않는다는 의미입니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"사실 Q-learning과 NN을 결합시키려는 시도는 매우 오래전부터 있었습니다. 하지만 저 2가지 문제를 해결해 이를 성공적으로 구현한 것은 2013년 DeepMind의 연구팀이었습니다. 이들은 Q-learning을 이용하여 Atari 게임을 플레이하는 AI를 만들었는데, 이것이 바로 DQN입니다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"DQN paper: \",[\"$\",\"a\",null,{\"href\":\"https://nature.com/articles/nature14236\",\"children\":\"https://nature.com/articles/nature14236\"}],\"\\n한번쯤 읽어보시길 추천드립니다.\"]}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"문제점\",\"className\":\" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"기존의 문제가 뭘까요?\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Correlations between samples(샘플간의 상관관계)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Non-stationary targets(움직이는 타겟)\"}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이겁니다. 이를 해결하기 위해 DeepMind 팀은 간단한 솔류션을 제시했습니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"한번 생각해 봅시다. 미로를 탈출한다고 했을때, 혹은 이전처럼 막대기를 새운다 했을때 0.1초전과 지금의 상태는 많이 다를까요? 음 그렇진 않거 같습니다. 상당히 유사한 상태일 것입니다. action을 취할시 환경이 급격히 바뀌는게 아닌 조금씩 바뀌기 때문에, 받아오는 데이터들 혹은 sample 들의 연관성이 유사하단 점이 바로 문젭니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TODO: Linear regression 그래프 예제 필요\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"두번째는 타켓이 움직인다 라는 겁니다.\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"min\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"mi\",null,{\"children\":\"θ\"}]]}],[\"$\",\"munderover\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}],[\"$\",\"mi\",null,{\"children\":\"T\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"r\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"max\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}]]}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\min_{\\\\theta} \\\\sum_{t=0}^T [\\\\hat{Q}(s_t, a_t|\\\\theta) - (r_t + \\\\gamma \\\\max_{a'}\\\\hat{Q}(s_{t+1}, a'|\\\\theta))]^2\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이전 공식에서 주의해서 보아야 할것이 두부분 있습니다.\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\hat{Q}(s_t, a_t|\\\\theta)\\n\"}]]}]}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"r\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"max\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}]]}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"(r_t + \\\\gamma \\\\max_{a'}\\\\hat{Q}(s_{t+1}, a'|\\\\theta))\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이 두 Q값이 서로 같은 신경망을 통해 계산되기 때문에, 이 두 Q값이 서로 영향을 주게 됩니다. 이는 Non-stationary targets 라는 문제를 발생시킵니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\hat{Q}(s_t, a_t|\\\\theta)\"}]]}]}]}],\" 부분에서 다음 상태에 가까워 지기 위해 네트워크를 업데이트 시키고 그 다음 계산인 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"r\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"max\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}]]}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"(r_t + \\\\gamma \\\\max_{a'}\\\\hat{Q}(s_{t+1}, a'|\\\\theta))\"}]]}]}]}],\" 부분에서는 업데이트된 네트워크를 사용하고 다시 업데이트를 시킵니다. 확실히 문제가 발생할 수 밖에 없습니다.\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"DQN's three solutions\",\"className\":\" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이 문제를 해결하기 위해 DeepMind 팀은 3가지 솔루션을 제시했습니다.\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Go deep: 더 깊은 신경망을 사용한다.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Capture and replay: Correlations between samples(샘플간의 상관관계)를 해결하기 위해 sample을 저장하고 랜덤하게 뽑아서 학습한다.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Separate networks: Non-stationary targets(움직이는 타겟)를 해결하기 위해 2개의 네트워크를 사용한다.\"}],\"\\n\"],\"className\":\"list-decimal ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Go deep\",\"className\":\" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"시원시원한 생각이죠, 이전엔 하나의 layer만 사용한걸 늘리면 되겠다는 생각입니다. 이는 더 복잡한 문제를 풀 수 있게 해줍니다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"End-to-end learning of values Q(S, a) from pixels s\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Input state s is stack of raw pixels from last 4 frames\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Output is Q(s, a) for 18 joystick/button positions\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Reward is change in score for that frame\"}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TODO: 위 내용 이해 필요, 설명 없었음\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Capture and replay\",\"className\":\" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"굉장히 중유한 솔루션 입니다. 너무 연관있는 데이터들로 학습을 시키니 학습이 잘 돼지 않았던 문제를 해결하기 위해 experience replay라는 방법을 사용합니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Agent 에게 action을 취하게 하는 루프를 돌면 이 action을 통해 상태를 받아오게 돼는데 이전엔 바로바로 학습을 시켰습니다. 이를 바꿔숴 중간에 버퍼에 저장을 한다음, 이 버퍼가 다 차면 혹은 일정한 시간이 지나면 해당 버퍼의 담겨진 데이터중 랜덤으로 하나 뽑아서 학습을 시킵니다.\\\\\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TODO: 사진\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TODO: 의사 코드 사진 필요\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Store transitions (s, a, r, s') in replay memory D\"}],\": action을 취한다음 D 라는 버퍼에다가 상태, 액션, 보상, 다음 상태를 저장합니다.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Sample random minibatch of transitions (s, a, r, s') from D\"}],\": D에서 랜덤하게 샘플을 뽑아 mini batch를 만들어 이걸 가지고 학습을 진행합니다.\"]}],\"\\n\"],\"className\":\"list-disc ml-12 space-y-2 my-3\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"아주 간단한 아이디어지만 왜 될까요?\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"눈치 채신분들도 많겠지만 이렇게 해봅시다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"버퍼에 어느정도 데이터가 쌓어셔 이걸 그래프로 표현해보겠습니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이런 그래프가 나왔을때 기존엔 편향된 데이터가 학습이 될수 있었지만 이들중 몇개만 랜덤으로 뽑아 학습을 하게 되면 우리가 원했던 기울기의 그래프가 나올 가능성이 훨씬 크지 않을까요? 아주 심플한 아이디어지만 실제로 매우 잘 작동합니다.\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Separate networks\",\"className\":\" text-2xl md:text-3xl font-bold my-5 text-purple-600 hover:text-purple-800 transition-colors duration-200\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이또한 매우 심플한 아이디어죠, 사용하는 NN가 같아 Non-stationary targets 문제가 발생했는데, 이를 해결하기 위해 2개의 네트워크를 사용합니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"공식에 익숙해 졌을거라 생각하니 바로 공식부터 보여드리면 이렇습니다.\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"min\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"mi\",null,{\"children\":\"θ\"}]]}],[\"$\",\"munderover\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}],[\"$\",\"mi\",null,{\"children\":\"T\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"r\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"max\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}]]}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"children\":\"ˉ\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\min_{\\\\theta} \\\\sum_{t=0}^T [\\\\hat{Q}(s_t, a_t|\\\\theta) - (r_t + \\\\gamma \\\\max_{a'}\\\\hat{Q}(s_{t+1}, a'|\\\\bar{\\\\theta}))]^2\\n\"}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"양쪽 Q의 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"θ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\theta\"}]]}]}]}],\" 가 다르다는것을 바로 눈치채실수 있을겁니다. 이는 서로 다른 NN을 사용한다는 의밉니다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"이때 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\hat{Q}(s_t, a_t|\\\\theta)\"}]]}]}]}],\" 에서 사용돼는 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"θ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\theta\"}]]}]}]}],\" 를 policy network라고 부르고, \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"r\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"max\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}]]}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"Q\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"children\":\"ˉ\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"(r_t + \\\\gamma \\\\max_{a'}\\\\hat{Q}(s_{t+1}, a'|\\\\bar{\\\\theta}))\"}]]}]}]}],\" 에서 사용되는 \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"θ\"}],[\"$\",\"mo\",null,{\"children\":\"ˉ\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\bar{\\\\theta}\"}]]}]}]}],\" 를 target network라고 부릅니다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"중요한점은 학습을 시킬때는 policy network 많을 업데이트 시킵니다. target network는 움직이지 않고 있다가 policy network가 일정한 시간이 지나거나 일정한 횟수만큼 업데이트 될때마다 policy network의 weight를 target network로 복사합니다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TODO: 의사코드\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"정말 심플하지만 이또한 정말 잘 작동합니다.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"요약\",\"className\":\" text-3xl md:text-4xl font-extrabold my-6 text-transparent bg-clip-text bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TODO: 의사코드와 요약\"}]]}]}]\n"])</script></body></html>