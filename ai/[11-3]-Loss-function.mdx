# Linear Regression
기본적인 딥러닝에 대해 소개했습니다. 이젠 기본적인 선형 회귀에 대해 알아보겠습니다. 선형 회귀는 가장 기본적인 머신러닝 알고리즘 중 하나입니다. 선형 회귀는 데이터의 경향성을 가장 잘 설명하는 하나의 직선을 찾는 알고리즘입니다.

먼저 이러한 데이터가 있다 가정해 보겠습니다.
| x(hours) | y(score) |
|----------|----------|
| 10       | 90       |
| 9        | 80       |
| 3        | 50       |
| 2        | 30       |

이 데이터는 x 시간 공부를 했을 때 y 점수를 얻었다는 데이터입니다. 이 데이터를 이용하여 Super vised learning을 한다 가정해 보겠습니다. 결과적으로 0 ~ 100 까지의 점수를 예측하는것이 목표이고 이러한 형태의 ML을 Super vised learning 중에서도 Regression이라고 합니다.

이러한 트레이닝 데이터를 가지고 train을 수행하면 regression 모델이 만들어 집니다. 쉽게 말해 그냥 Agent를 만든다고 생각하시면 됩니다. 그리고 이후 7시간이라는 IN을 던지면 regression은 학습된 데이터를 기반으로 적절한 OUT을 내놓습니다.

이러한 방식을 Linear Regression 이라고 합니다.

설명을 간단히 하기 위해 테이블을 더 간단히 하겠습니다. 이 모델을 가지고 regression 모델을 만들려고 하는 겁니다.

| x | y |
|---|---|
| 1 | 1 |
| 2 | 2 |
| 3 | 3 |

이러한 데이터를 그래프로 표현해보면 다음과 같습니다.